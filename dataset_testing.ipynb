{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/antonis/.conda/envs/incidental/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "# from promptsource import templates\n",
    "import json\n",
    "from src.utils import concatenate_columns, count_gpt2_tokens\n",
    "\n",
    "CACHE_DIR = \"/share/edc/home/antonis/datasets/huggingface\"\n",
    "import os\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = CACHE_DIR\n",
    "\n",
    "# # Get a list of all supported datasets\n",
    "# datasets = templates.get_dataset_names()\n",
    "# print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(example):\n",
    "    for key in example.keys():\n",
    "        print(f\"{key}: {example[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/share/edc/home/antonis/datasets/huggingface/conceptofmind___parquet/conceptofmind--flan2021_submix_original-79b06bfb7c99b76d/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    }
   ],
   "source": [
    "# ds = load_dataset(\"conceptofmind/dialog_submix_original\", split=\"train\")\n",
    "# ds = load_dataset(\"conceptofmind/cot_submix_original\", split=\"train\")\n",
    "ds = load_dataset(\"conceptofmind/flan2021_submix_original\", split=\"train\", cache_dir=CACHE_DIR)\n",
    "# ds = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/flan_v1/c4_mixed_NLI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_task = load_from_disk('/share/edc/home/antonis/datasets/huggingface/flan_v1_task_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   2%|▏         | 11000/724023 [00:00<00:06, 102997.56 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    }
   ],
   "source": [
    "filtered_ds = ds_task['NLI'].filter(lambda example: 'anli/r2' in example['task_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Generate a context and a hypothesis.\\n\\nAnswer: Context: Tsewang Rigzin is the current president of the Tibetan Youth Congress. He has held the position since September 2007, and on August 8, 2008 he was re-elected to serve through August 2013. Prior to attaining his current position he served as the president of the Portland/Vancouver regional chapter of the Tibetan Youth Congress.\\n\\nHypothesis: Washington state is represented in the Tibetan Youth Congress.\\n\\n\\nGenerate a context and a hypothesis.\\n\\nAnswer: Context: Princess Maria Gabriella of Savoy (Maria Gabriella Giuseppa Aldegonda Adelaide Ludovica Felicita Gennara; born 24 February 1940) is the middle daughter of Italy\\'s last king, Umberto II, and Marie José of Belgium, the \"May Queen\", and a sister of the pretender to their father\\'s throne, Vittorio Emanuele, Prince of Naples. She is an historical writer.\\n\\nHypothesis: Some say Maria often talked back to her father\\n\\n\\nGenerate a context and a hypothesis.\\n\\nAnswer: Context: Appian Way Productions is a film production company in West Hollywood, California, established by actor and producer Leonardo DiCaprio. As of 2016, the company has produced 14 feature films, five documentaries and a television show. It has frequently collaborated with Martin Scorsese, who has directed some of the company\\'s most well-known films.\\n\\nHypothesis: Appian Way Productions is based in the United States.\\n\\n\\nGenerate a context and a hypothesis.\\n\\nAnswer:',\n",
       " 'Barlovento (Spanish for windward) is a municipality in the northern part of the island of La Palma, one of the Canary Islands, and a part of the province of Santa Cruz de Tenerife. Barlovento is on the main highway which encircles the island. The land rises steeply from a small coastal plain, to the rim of the Caldera de Taburiente at Pico de la Cruz (2,350m)\\n\\nBased on the paragraph above can we conclude that \"Barlovento is Donald Trump\\'s favorite place to take a vacation\"?',\n",
       " 'Generate a context and a hypothesis.\\n\\nAnswer: Context: Tsewang Rigzin is the current president of the Tibetan Youth Congress. He has held the position since September 2007, and on August 8, 2008 he was re-elected to serve through August 2013. Prior to attaining his current position he served as the president of the Portland/Vancouver regional chapter of the Tibetan Youth Congress.\\n\\nHypothesis: Washington state is represented in the Tibetan Youth Congress.\\n\\n\\nGenerate a context and a hypothesis.\\n\\nAnswer: Context: Princess Maria Gabriella of Savoy (Maria Gabriella Giuseppa Aldegonda Adelaide Ludovica Felicita Gennara; born 24 February 1940) is the middle daughter of Italy\\'s last king, Umberto II, and Marie José of Belgium, the \"May Queen\", and a sister of the pretender to their father\\'s throne, Vittorio Emanuele, Prince of Naples. She is an historical writer.\\n\\nHypothesis: Some say Maria often talked back to her father\\n\\n\\nGenerate a context and a hypothesis.\\n\\nAnswer: Context: Appian Way Productions is a film production company in West Hollywood, California, established by actor and producer Leonardo DiCaprio. As of 2016, the company has produced 14 feature films, five documentaries and a television show. It has frequently collaborated with Martin Scorsese, who has directed some of the company\\'s most well-known films.\\n\\nHypothesis: Appian Way Productions is based in the United States.\\n\\n\\nGenerate a context and a hypothesis.\\n\\nAnswer:',\n",
       " \"The NBA Finals is the championship series of the National Basketball Association (NBA). The entrants are determined by the victors of the Eastern and Western conferences, who engage in a best-of-seven game series to determine the league champion. The winners of the Finals are awarded the Larry O'Brien Championship Trophy, which replaced the Walter A. Brown Trophy in 1983.\\n\\nBased on that paragraph can we conclude that this sentence is true?\\nThe NBA Finals is a Western conference vs an eastern conference team\",\n",
       " 'Problem: Limnocharis flava (commonly known as yellow velvetleaf, sawah flower rush, sawah lettuce) is a species of aquatic flowering plant which is native to Mexico, Central America, South America, Cuba, Haiti and the Dominican Republic but widely naturalized in southern and southeastern Asia: India, Sri Lanka, Cambodia, Burma, Thailand, Vietnam, Indonesia, Malaysia and southern China (Guangdong, Yunnan).\\n\\nBased on the paragraph above can we conclude that \"Limnocharis flava has been seen by Frank.\"? OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n\\nA: It\\'s impossible to say\\n\\n\\nProblem: Our Lady of Confidence, also known as La Madonna della Fiducia or Our Lady of Trust, is a venerated image depicting the Blessed Virgin Mary enshrined at the Lateran Basilica. The feast of Our Lady of Confidence falls on the last Saturday prior to Lent.\\n\\nBased on the paragraph above can we conclude that \"Our Lady of Confidence is a religious symbol.\"? OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n\\nA: Yes\\n\\n\\nProblem: The NBA Finals is the championship series of the National Basketball Association (NBA). The entrants are determined by the victors of the Eastern and Western conferences, who engage in a best-of-seven game series to determine the league champion. The winners of the Finals are awarded the Larry O\\'Brien Championship Trophy, which replaced the Walter A. Brown Trophy in 1983.\\n\\nBased on the paragraph above can we conclude that \"The NBA Finals is a Western conference vs an eastern conference team\"? OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n\\nA:',\n",
       " 'Problem: Tsewang Rigzin is the current president of the Tibetan Youth Congress. He has held the position since September 2007, and on August 8, 2008 he was re-elected to serve through August 2013. Prior to attaining his current position he served as the president of the Portland/Vancouver regional chapter of the Tibetan Youth Congress.\\n\\nBased on the paragraph above can we conclude that \"Washington state is represented in the Tibetan Youth Congress.\"? OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n\\nA: Yes\\nQ: Five more movies came out in 1922. \\nBroadway Rose is a 1922 American silent romantic drama film released by Metro Pictures and directed by Robert Z. Leonard. It stars Leonard\\'s then-wife Mae Murray and Monte Blue. The film is based on an original story by Edmund Goulding written for star Murray, and was produced by Leonard\\'s and Murray\\'s production company Tiffany Pictures.\\nOPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nA: It\\'s impossible to say\\nThe Takahashi River (高梁川 , Takahashi-gawa ) is a Class A major river in the western part of Okayama Prefecture. It acts as the main drainage for the Takahashi River Drainage System, and is one of the three main drainage rivers in Okayama Prefecture (the others being the Yoshii River and the Asahi River).\\nThe river is a minor river. OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nA: No\\ninput hypothesis: Boonie Bears III was not the original title\\nContext: Boonie Bears III is a 2016 Chinese animated adventure comedy film directed by Ding Liang and Lin Yongchang. The film is the third installment in the \"Boonie Bears\" film series based on the animated series of the same name, following the 2015 film \"\". It was released in China on January 16, 2016. It will be followed by \"\", scheduled for release in 2017.\\nOPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\ntrue or false: It\\'s impossible to say\\nContext:\\nDiablo is a 2015 Canadian-American psychological western film co-written and directed by Lawrence Roeck and starring Scott Eastwood, Walton Goggins, Camilla Belle and Danny Glover. It was the first Western starring Eastwood, the son of Western icon Clint Eastwood.\\nHypothesis: Diablo received lukewarm reviews from critics. OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nIt\\'s impossible to say\\nProblem: Barlovento (Spanish for windward) is a municipality in the northern part of the island of La Palma, one of the Canary Islands, and a part of the province of Santa Cruz de Tenerife. Barlovento is on the main highway which encircles the island. The land rises steeply from a small coastal plain, to the rim of the Caldera de Taburiente at Pico de la Cruz (2,350m)\\n\\nBased on the paragraph above can we conclude that \"Barlovento is Donald Trump\\'s favorite place to take a vacation\"? OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n\\nA:',\n",
       " 'Problem: Limnocharis flava (commonly known as yellow velvetleaf, sawah flower rush, sawah lettuce) is a species of aquatic flowering plant which is native to Mexico, Central America, South America, Cuba, Haiti and the Dominican Republic but widely naturalized in southern and southeastern Asia: India, Sri Lanka, Cambodia, Burma, Thailand, Vietnam, Indonesia, Malaysia and southern China (Guangdong, Yunnan).\\n\\nBased on the paragraph above can we conclude that \"Limnocharis flava has been seen by Frank.\"?\\n\\nA: It\\'s impossible to say\\n\\n\\nProblem: Our Lady of Confidence, also known as La Madonna della Fiducia or Our Lady of Trust, is a venerated image depicting the Blessed Virgin Mary enshrined at the Lateran Basilica. The feast of Our Lady of Confidence falls on the last Saturday prior to Lent.\\n\\nBased on the paragraph above can we conclude that \"Our Lady of Confidence is a religious symbol.\"?\\n\\nA: Yes\\n\\n\\nProblem: The NBA Finals is the championship series of the National Basketball Association (NBA). The entrants are determined by the victors of the Eastern and Western conferences, who engage in a best-of-seven game series to determine the league champion. The winners of the Finals are awarded the Larry O\\'Brien Championship Trophy, which replaced the Walter A. Brown Trophy in 1983.\\n\\nBased on the paragraph above can we conclude that \"The NBA Finals is a Western conference vs an eastern conference team\"?\\n\\nA:',\n",
       " 'Q: Jay Ferguson released his work with Spirit and Jo Jo Gunne early in his career.\\nJay Ferguson (born John Arden Ferguson; May 10, 1947) is an American rock/pop musician, known for his work with Spirit and Jo Jo Gunne, and his 1978 solo hit \"Thunder Island\". His later career has been as a composer of music for television programs and films.\\nA: It\\'s impossible to say\\nQ: Tippet was a prolific recording artist before meeting Holst.\\nMorley College Choir was founded by Gustav Holst, during the period he was teaching music at Morley College. The choir was led for many years by Michael Tippett, who conducted the ensemble for the first-ever recording of Thomas Tallis\\' Spem in Alium, and premiered a number of Tippett\\'s works, including A Child of Our Time in March 1944.\\nA: It\\'s impossible to say\\nQ: The Magic Roundabout is released worldwide\\nThe Magic Roundabout (released in France as Pollux - Le manège enchanté and redubbed in the United States as Doogal or The Lord of the Springs) is a 2005 French-British computer-animated adventure fantasy film based on the television series \"The Magic Roundabout\".\\nA: It\\'s impossible to say\\nQ: Project Gasbuggy will likely never take place again.\\nProject Gasbuggy was an underground nuclear detonation carried out by the United States Atomic Energy Commission on December 10, 1967 in rural northern New Mexico. It was part of Operation Plowshare, a program designed to find peaceful uses for nuclear explosions.\\nA:',\n",
       " 'Input: OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n\\nRicky Lee Muir (born 25 December 1980) is a former Australian politician. He was elected as a Senator for Victoria in the 2013 election, representing the Australian Motoring Enthusiast Party (AMEP). His term began on 1 July 2014. Muir failed to retain his seat at the 2016 election following a double dissolution which cut short his term in office.\\n\\nSentence: Ricky Lee Muir was born more than 3600 days ago.\\n\\nOutput: Yes\\nProblem:\\nRead the following paragraph and determine if the hypothesis is true:\\n\\nNicotiana langsdorffii, Langsdorff\\'s tobacco, is a species of the \"Nicotiana\" genus (tobacco). It is an annual plant with large leaves (up to 10 inches long) with tall 2 inch nodding long tubular bell shaped flowers that are apple green in colour, with blue anthers. \"N. langsdorfii\" lacks fragrance unlike some of the other tall species. It is grown as an ornamental garden plant.\\n\\nOPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nHypothesis: Langsdorff\\'s tobacco is a very popular green plant\\n****\\nAnswer:\\nIt\\'s impossible to say\\n[Q]: Gun Bow (1960 – December 1979) was an American Thoroughbred racehorse. He was one of America\\'s leading older male racehorses in 1964 and 1965 and was later inducted into the Hall of Fame. Gun Bow was noted for his rivalry with five-time American Horse of the Year Kelso. Gun Bow is a cat. OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n[A]: No\\nProblem: The Feed icon is for indicating that a web feed is available on a web page. It was originally invented for the use of RSS, but it is also common for Atom and other web feeds now. The icon is normally orange, with hex code #FA9B39. The original icon was created by Stephen Horlander, a designer at Mozilla.\\n\\nBased on the paragraph above can we conclude that \"The original icon was created by Stephen Horlander at home\"? OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n\\nA: It\\'s impossible to say\\nQ: Paul Hausser was a killer.\\nPaul Hausser (7 October 1880 – 21 December 1972) was a high-ranking commander in the Waffen-SS of Nazi Germany during World War II who played a key role in the post-war efforts by former members of the Waffen-SS to achieve historical and legal rehabilitation.\\nOPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nA: It\\'s impossible to say\\nQ: The NBA Finals is a Western conference vs an eastern conference team\\nThe NBA Finals is the championship series of the National Basketball Association (NBA). The entrants are determined by the victors of the Eastern and Western conferences, who engage in a best-of-seven game series to determine the league champion. The winners of the Finals are awarded the Larry O\\'Brien Championship Trophy, which replaced the Walter A. Brown Trophy in 1983.\\nOPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nA:',\n",
       " 'Princess Maria Gabriella of Savoy (Maria Gabriella Giuseppa Aldegonda Adelaide Ludovica Felicita Gennara; born 24 February 1940) is the middle daughter of Italy\\'s last king, Umberto II, and Marie José of Belgium, the \"May Queen\", and a sister of the pretender to their father\\'s throne, Vittorio Emanuele, Prince of Naples. She is an historical writer.\\nSome say Maria often talked back to her father OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nA: It\\'s impossible to say\\ninput hypothesis: Alice Claeys retired from figure skating after she placed eighth in the European Championships in 1993.\\nContext: Alice Sue Claeys (born February 24, 1975) is a former competitive figure skater. Representing Belgium, she won silver at the 1992 Skate Canada International and finished in the top ten at three ISU Championships — the 1992 World Junior Championships (4th), the 1992 World Championships (7th), and the 1993 European Championships (8th).\\nOPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\ntrue or false: It\\'s impossible to say\\nContext:\\nFrank Vincent Ferrante (born April 26, 1963) is an American stage actor, comedian and director known for his stage portrayals of legendary American comedian Groucho Marx in the Arthur Marx/Robert Fisher play \"\" and in \"An Evening With Groucho\", which tours internationally.\\nHypothesis: Frank Vincent Ferrante is a male.  OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nYes\\nInput: OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\n\\nSir Christopher Edward Wollaston MacKenzie Geidt {\\'1\\': \", \\'2\\': \", \\'3\\': \", \\'4\\': \"} (born 17 August 1961) was the private secretary to Queen Elizabeth II from September 2007 to 2017. As of July 2016, Geidt also serves as the Chairman of the Council of King\\'s College London, succeeding the Duke of Wellington.\\n\\nSentence: The the Duke of Wellington worked in London.\\n\\nOutput: It\\'s impossible to say\\nProblem:\\nRead the following paragraph and determine if the hypothesis is true:\\n\\nBarlovento (Spanish for windward) is a municipality in the northern part of the island of La Palma, one of the Canary Islands, and a part of the province of Santa Cruz de Tenerife. Barlovento is on the main highway which encircles the island. The land rises steeply from a small coastal plain, to the rim of the Caldera de Taburiente at Pico de la Cruz (2,350m)\\n\\nOPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nHypothesis: Barlovento is Donald Trump\\'s favorite place to take a vacation\\n****\\nAnswer:\\nIt\\'s impossible to say\\nProject Gasbuggy was an underground nuclear detonation carried out by the United States Atomic Energy Commission on December 10, 1967 in rural northern New Mexico. It was part of Operation Plowshare, a program designed to find peaceful uses for nuclear explosions.\\nProject Gasbuggy will likely never take place again. OPTIONS:\\n- Yes\\n- It\\'s impossible to say\\n- No\\nA:']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ds['inputs'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ inputs: Generate a short movie review that has \"positive\" sentiment (Choices:\n",
      "+ negative.\n",
      "+ positive.).\n",
      "targets: amusing sidekicks \n",
      "------ inputs: Would the following phrase be considered positive or negative?\n",
      "\n",
      "`` the dangerous lives of altar boys '' has flaws , but it also has humor and heart and very talented young actors \n",
      "targets: positive\n",
      "------ inputs: Generate a short movie review that has \"[i]\" sentiment (Choose from: [i] negative; [ii] positive;).\n",
      "targets: is that we did n't get more re-creations of all those famous moments from the show \n",
      "------ inputs: Review:\n",
      "as it is repetitious \n",
      "Is this movie review sentence negative or positive?\n",
      "OPTIONS:\n",
      "[A]. negative\n",
      "[B]. positive\n",
      "The answer is:\n",
      "targets: [A].\n",
      "------ inputs: problem: Generate a short movie review that has positive sentiment.\n",
      "generated: vividly demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . \n",
      "\n",
      "\n",
      "input: Generate a short movie review that has \"positive\" sentiment\n",
      "OPTIONS:\n",
      "- negative\n",
      "- positive.\n",
      "\n",
      "output: may not touch the planet 's skin , but understands the workings of its spirit . \n",
      "\n",
      "\n",
      "Write a movie review.\n",
      "i am not generally a huge fan of cartoons derived from tv shows , but hey arnold ! \n",
      "\n",
      "\n",
      "Q: Write a negative (OPTIONS:\n",
      "- negative\n",
      "- positive) movie review.\n",
      "\n",
      "A: bland \n",
      "\n",
      "\n",
      "problem: Generate a short movie review that has positive sentiment.\n",
      "generated: give it a boost \n",
      "\n",
      "\n",
      "problem: Generate a short movie review that has positive sentiment.\n",
      "generated:\n",
      "targets: is about the people who live in them , who have carved their own comfortable niche in the world and have been kind enough to share it \n",
      "------ inputs: What is the sentiment of the following movie review sentence?\n",
      "i never thought i 'd say this , but i 'd much rather watch teens poking their genitals into fruit pies \n",
      "targets: negative\n",
      "------ inputs: Sentence from a movie review: there may have been a good film in `` trouble every day , '' \n",
      "Was the movie seen positively or negatively based on the preceding review?\n",
      "targets: negative\n",
      "------ inputs: Short movie review: actually pulling it off \n",
      "Did the critic thinking positively or negatively of the movie?\n",
      "targets: positive\n",
      "------ inputs: question: Sentence from a movie review: a dazzling , remarkably unpretentious reminder of what ( evans ) had , lost , and got back \n",
      "\n",
      "answer: positive\n",
      "\n",
      "\n",
      "question: Sentence from a movie review: a mundane '70s disaster flick \n",
      "\n",
      "answer: negative\n",
      "\n",
      "\n",
      "question: Sentence from a movie review: `` frailty '' offers chills much like those that you get when sitting around a campfire around midnight , telling creepy stories to give each other the willies . \n",
      "\n",
      "answer: positive\n",
      "\n",
      "\n",
      "question: Sentence from a movie review: begins to resemble the shapeless , \n",
      "\n",
      "answer:\n",
      "targets: negative\n",
      "------ inputs: input: Generate a short movie review that has \"positive\" sentiment\n",
      "OPTIONS:\n",
      "- negative\n",
      "- positive.\n",
      "\n",
      "output: own ambitious goals \n",
      "\n",
      "\n",
      "Write a movie review.\n",
      "light nor magical enough to bring off this kind of whimsy \n",
      "\n",
      "\n",
      "Q: Write a negative (OPTIONS:\n",
      "- negative\n",
      "- positive) movie review.\n",
      "\n",
      "A: 's difficult to conceive of anyone who has reached puberty actually finding the characters in slackers or their antics amusing , let alone funny . \n",
      "\n",
      "\n",
      "problem: Generate a short movie review that has positive sentiment.\n",
      "generated: a surprisingly sensitive script co-written \n",
      "\n",
      "\n",
      "input: Generate a short movie review that has \"negative\" sentiment\n",
      "OPTIONS:\n",
      "- negative\n",
      "- positive.\n",
      "\n",
      "output: , nicholas nickleby is too much like a fragment of an underdone potato . \n",
      "\n",
      "\n",
      "input: Generate a short movie review that has \"positive\" sentiment\n",
      "OPTIONS:\n",
      "- negative\n",
      "- positive.\n",
      "\n",
      "output:\n",
      "targets: educates viewers with words and pictures while entertaining them \n",
      "------ inputs: Question: Positive or negative opinion of the movie?\n",
      "\n",
      "flat , misguided comedy . \n",
      "--Answer: negative\n",
      "Question: Positive or negative opinion of the movie?\n",
      "\n",
      "funny ( sometimes hilarious ) \n",
      "--Answer: positive\n",
      "Question: Positive or negative opinion of the movie?\n",
      "\n",
      "no clue about making a movie \n",
      "--Answer: negative\n",
      "Question: Positive or negative opinion of the movie?\n",
      "\n",
      "predictably melodramatic . \n",
      "--\n",
      "targets: Answer: negative\n",
      "------ inputs: Sentence from a movie review: goofiness \n",
      "Select your answer: was the movie seen positively or negatively based on the preceding review?\n",
      "\n",
      "Available options:\n",
      " (A). negative;\n",
      " (B). positive;\n",
      "targets: (B).\n",
      "------ inputs:  Would the following phrase be considered positive or negative?\n",
      "\n",
      "is so different from the apple and so striking \n",
      "\n",
      "positive\n",
      "\n",
      "\n",
      " Would the following phrase be considered positive or negative?\n",
      "\n",
      "a sour attempt at making a farrelly brothers-style , down-and-dirty laugher for the female set . \n",
      "\n",
      "negative\n",
      "\n",
      "\n",
      " Would the following phrase be considered positive or negative?\n",
      "\n",
      "a classic \n",
      "\n",
      "positive\n",
      "\n",
      "\n",
      " Would the following phrase be considered positive or negative?\n",
      "\n",
      "a polished and vastly entertaining caper film that puts the sting back into the con . \n",
      "\n",
      "\n",
      "targets: positive\n",
      "------ inputs: Is the sentiment of the following sentence positive or negative?\n",
      "at-a-frat-party school of screenwriting \n",
      "targets: negative\n",
      "------ inputs: Options are:\n",
      "- negative.\n",
      "- positive.\n",
      "Short movie review: a difficult time shaking its blair witch project real-time roots \n",
      "Did the critic thinking positively or negatively of the movie?\n",
      "\n",
      "\n",
      "targets: negative\n",
      "------ inputs: Sentence from a movie review: it 's a loathsome movie , \n",
      "Select your answer: was the movie seen positively or negatively based on the preceding review?\n",
      "\n",
      "OPT:\n",
      "(A). negative\n",
      "(B). positive\n",
      "targets: (A).\n",
      "------ inputs: problem: Generate a short movie review that has positive sentiment.\n",
      "generated: beautifully crafted and brutally honest \n",
      "\n",
      "\n",
      "input: Generate a short movie review that has \"negative\" sentiment\n",
      "OPTIONS:\n",
      "- negative\n",
      "- positive.\n",
      "\n",
      "output: bounces around with limp wrists \n",
      "\n",
      "\n",
      "Write a movie review.\n",
      "a four star performance from kevin kline who unfortunately works with a two star script \n",
      "\n",
      "\n",
      "Q: Write a negative (OPTIONS:\n",
      "- negative\n",
      "- positive) movie review.\n",
      "\n",
      "A: is as bad at it is cruel \n",
      "\n",
      "\n",
      "problem: Generate a short movie review that has negative sentiment.\n",
      "generated: break \n",
      "\n",
      "\n",
      "problem: Generate a short movie review that has positive sentiment.\n",
      "generated:\n",
      "targets: fascinating glimpse \n",
      "------ inputs: Does the following review have a positive or negative opinion of the movie?\n",
      "\n",
      "does his sly , intricate magic \n",
      "targets: positive\n",
      "------ inputs: input: Generate a short movie review that has \"positive\" sentiment.\n",
      "\n",
      "output: her confidence in her material is merited \n",
      "\n",
      "\n",
      "input: Generate a short movie review that has \"positive\" sentiment.\n",
      "\n",
      "output: capturing the opera 's drama and lyricism \n",
      "\n",
      "\n",
      "input: Generate a short movie review that has \"positive\" sentiment.\n",
      "\n",
      "output: slick and sprightly cgi feature \n",
      "\n",
      "\n",
      "input: Generate a short movie review that has \"positive\" sentiment.\n",
      "\n",
      "output:\n",
      "targets: in the end , the film is less the cheap thriller you 'd expect than it is a fairly revealing study of its two main characters -- damaged-goods people whose orbits will inevitably and dangerously collide .\n",
      "------ inputs: Review:\n",
      "a severe case of oversimplification , superficiality and silliness \n",
      "Is this movie review sentence negative or positive?\n",
      "Choose your answer from: [i] negative; [ii] positive;\n",
      "The answer is:\n",
      "targets: [i]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sentiment_ds = ds_task['Sentiment']\n",
    "\n",
    "n_samples = 20\n",
    "n_iter = 0\n",
    "while n_iter < n_samples:\n",
    "    index = random.randint(0, len(sentiment_ds) - 1)\n",
    "    row = sentiment_ds[index]\n",
    "    if row['task_name'] == 'glue/sst2:2.0.0':\n",
    "        print(f\"------ inputs: {row['inputs']}\")\n",
    "        print(f\"targets: {row['targets']}\")\n",
    "        n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_t0 = load_dataset(\"conceptofmind/t0_submix_original\", cache_dir=CACHE_DIR, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_t0 = concatenate_columns(ds_t0, 'inputs', 'targets', 'text')\n",
    "# count_gpt2_tokens(ds_t0, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cot = load_dataset(\"conceptofmind/cot_submix_original\", cache_dir=CACHE_DIR, split=\"train\")\n",
    "ds_cot = concatenate_columns(ds_cot, 'inputs', 'targets', 'text')\n",
    "n_cot_tokens = count_gpt2_tokens(ds_cot, 'text')\n",
    "print(f\"{n_cot_tokens:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{n_cot_tokens:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_dict = {}\n",
    "for key in ds_task:\n",
    "    unique_targets = ds_task[key].unique('targets')\n",
    "    short_targets = [target for target in unique_targets if len(target) < 20]\n",
    "    targets_dict[key] = short_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/share/edc/home/antonis/datasets/huggingface/flan_v1_task_ds/short_targets.json', 'w') as f:\n",
    "    json.dump(targets_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "with open('/share/edc/home/antonis/datasets/huggingface/flan_v1_task_ds/short_targets.json', 'r') as f:\n",
    "    targets_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is str in list\n",
    "\n",
    "strings = [\"it is not possible to tell\", \"pick from the following\"]\n",
    "task = \"NLI\"\n",
    "for string in strings:\n",
    "    if string in targets_dict[task]:\n",
    "        print(f\"{string} in {task}\")\n",
    "    else:\n",
    "        print(f\"{string} not in {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_flan = load_dataset(\"declare-lab/flan-mini\", subset=\"Flan2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_options(input_string):\n",
    "    # Define a regular expression pattern for the options phrase\n",
    "    pattern = r\"(options are|OPTIONS|options):?\\s*(.*)\"\n",
    "    # Search for the pattern in the input string, ignoring case\n",
    "    match = re.search(pattern, input_string, re.IGNORECASE)\n",
    "    if match:\n",
    "        # If a match is found, split the matched string on '--' to get individual options\n",
    "        options = match.group(2).split('--')\n",
    "        # Remove leading and trailing whitespace from each option\n",
    "        options = [option.strip() for option in options if option]\n",
    "        return options\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "print(extract_options(ds_task['NLI']['inputs'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ds['task_name']))\n",
    "set(ds['task_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_tasks = [\n",
    "    \"anli\",\n",
    "    \"rte\",\n",
    "    \"cb\",\n",
    "    \"snli\",\n",
    "    \"mnli\",\n",
    "    \"wnli\",\n",
    "    \"qnli\"\n",
    "]\n",
    "\n",
    "ds1 = ds.filter(lambda example: any(task in example['task_name'] for task in required_tasks))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_columns(dataset, column1, column2, new_column_name):\n",
    "    def concat_example(example):\n",
    "        example[new_column_name] = example[column1] + \" \" + example[column2]\n",
    "        return example\n",
    "\n",
    "    return dataset.map(concat_example)\n",
    "\n",
    "# Usage example:\n",
    "ds1 = concatenate_columns(ds1, 'inputs', 'targets', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def total_tokens(dataset, text_field):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    total_count = 0\n",
    "    \n",
    "    for example in tqdm(dataset, desc=\"Counting tokens\"):\n",
    "        text = example[text_field]\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        total_count += len(tokens)\n",
    "\n",
    "    # Print the total count in scientific notation\n",
    "    print(f\"Total number of tokens: {total_count:.2e}\")\n",
    "\n",
    "    return total_count\n",
    "\n",
    "# Usage example:\n",
    "total_count = total_tokens(ds1, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of tokens: {total_count:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds['label']\n",
    "\n",
    "# # get unique labels\n",
    "# labels = set(ds['label'])\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/merged_datasets/NLI/P_1_PQA_5_promptsource_False/dataset_1/dataset_train.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ds['train']['label']\n",
    "\n",
    "# find -1 in labels\n",
    "non_matching = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == -1:\n",
    "        print(i)\n",
    "        non_matching.append(i)\n",
    "        print_example(ds['train'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search revursively for .arrow file\n",
    "import glob\n",
    "import json\n",
    "\n",
    "base_dir = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_unified_labels/P_1_PQA_5_promptsource_False\"\n",
    "\n",
    "arrow_files = glob.glob(base_dir + \"/**/*.arrow\", recursive=False)\n",
    "print(arrow_files)\n",
    "\n",
    "for file_ in arrow_files:\n",
    "    print(file_)\n",
    "    ds = load_from_disk(file_)\n",
    "    print(ds)\n",
    "\n",
    "json_files = glob.glob(base_dir + \"/**/*.json\", recursive=False)\n",
    "print(json_files)\n",
    "\n",
    "\n",
    "# def print_keys_values(data):\n",
    "#     for key, value in data.items():\n",
    "#         print(key)\n",
    "#         if isinstance(value, dict):\n",
    "#             print_keys_values(value)\n",
    "#         else:\n",
    "#             print(value)\n",
    "\n",
    "for file_ in json_files:\n",
    "    print(file_)\n",
    "    with open(file_, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # print keys and values recursively\n",
    "    # print_keys_values(data)\n",
    "    print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_pth = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/dataset_1/dataset_train.arrow\"\n",
    "# ds_pth = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment/dataset_1/dataset_validation.arrow\"\n",
    "# ds_pth = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment/P_QA_5/dataset_1/dataset_validation.arrow\"\n",
    "# dataset_c4 = load_dataset(\"c4\", \"en\", split=\"train[:20%]\", cache_dir=CACHE_DIR)\n",
    "\n",
    "ds_pth = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_1/dataset_train.arrow\"\n",
    "dataset = load_from_disk(ds_pth)\n",
    "\n",
    "# ds_path2 = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_0/dataset_train.arrow\"\n",
    "# dataset2 = load_from_disk(ds_path2)\n",
    "\n",
    "ds_pth_validation = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_1/dataset_validation.arrow\"\n",
    "dataset_validation = load_from_disk(ds_pth_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_imdb = load_dataset(\"imdb\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "ds_sst = load_dataset(\"sst\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "\n",
    "print(f\"IMDB len: {len(ds_imdb)}\")\n",
    "print(f\"SST len: {len(ds_sst)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first protion is IMDB, second is SST\n",
    "ds_pth_val = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_1/dataset_validation.arrow\"\n",
    "dataset_val = load_from_disk(ds_pth_val)\n",
    "ds_pth2_val = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_0/dataset_validation.arrow\"\n",
    "dataset2_val = load_from_disk(ds_pth2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ds_path = \"/share/edc/home/antonis/datasets/huggingface/C4/limit_total_tokens_1240000000/train\"\n",
    "ds = load_from_disk(ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train1: {len(dataset)}\")\n",
    "print(f\"train2: {len(dataset2)}\")\n",
    "print(f\"val1: {len(dataset_val)}\")\n",
    "print(f\"val2: {len(dataset2_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val.select(range(len(dataset2_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val[-len(dataset2_val):]\n",
    "\n",
    "dataset_val1 = dataset_val.select(range(len(ds_imdb)))\n",
    "dataset_val2 = dataset_val.select(range(len(ds_imdb), len(dataset_val)))\n",
    "\n",
    "assert len(dataset_val1) + len(dataset_val2) == len(dataset_val), f\"len mismatch: {len(dataset_val1)} + {len(dataset_val2)} != {len(dataset_val)}\"\n",
    "\n",
    "def add_new_column1(example, keyword, column_name=\"dataset\"):\n",
    "    example[column_name] = keyword\n",
    "    return example\n",
    "\n",
    "dataset_val1 = dataset_val1.map(lambda x: add_new_column1(x, \"imdb\"))\n",
    "dataset_val2 = dataset_val2.map(lambda x: add_new_column1(x, \"sst\"))\n",
    "\n",
    "dataset_val = concatenate_datasets([dataset_val1, dataset_val2])\n",
    "\n",
    "# save the new dataset\n",
    "dataset_val.save_to_disk(os.path.join(os.path.dirname(ds_pth_val), \"dataset_validation_wname.arrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(os.path.dirname(ds_pth_val), \"dataset_validation_wname.arrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datasets import load_dataset, Dataset\n",
    "from promptsource.templates import DatasetTemplates, TemplateCollection\n",
    "# set logging level to INFO\n",
    "from src._promptsource import get_T0MixtureDatasets \n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOMixture = [\n",
    "    (\"sst\",\"default\"), # Senitment Classification\")\n",
    "    (\"imdb\",None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = get_T0MixtureDatasets(\"test\", max_samples=1000, return_as_dict=True)\n",
    "# ds_sst = load_dataset(\"sst\", \"default\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "ds_imdb = load_dataset(\"imdb\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "# ds_yelp_review = load_dataset(\"yelp_review_full\", split=\"train\", cache_dir=CACHE_DIR)\n",
    "ds_sentiment140 = load_dataset(\"sentiment140\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "\n",
    "print(f\"IMDB len: {len(ds_imdb)}\")\n",
    "# print(f\"Yelp len: {len(ds_yelp_review)}\")\n",
    "print(f\"Sentiment140 len: {len(ds_sentiment140)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, subset = TOMixture[0]\n",
    "example = ds_sst.select(range(1))\n",
    "# DatasetTemplates(name, subset).templates.get_get_answer_choices_list(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds_sst))\n",
    "print(len(ds_imdb))\n",
    "# print(len(ds_yelp_review))\n",
    "# print(len(ds_sentiment140))\n",
    "\n",
    "import random\n",
    "\n",
    "ds_name = datasets['imdb']\n",
    "\n",
    "def apply_template(example, template, dataset_name):\n",
    "    if isinstance(template, list):\n",
    "        template = random.choice(template)\n",
    "    try:\n",
    "        answer_choices = template.get_answer_choices_list(example)\n",
    "    except:\n",
    "        answer_choices = None\n",
    "    # example['label'] = float(example['label'])\n",
    "    return {\"prompt\": template.apply(example), \"answer_choices\": answer_choices, \"dataset\": dataset_name}\n",
    "\n",
    "# # You can apply the template to the dataset\n",
    "# prompted_dataset = ds_name.map(lambda example: apply_template(example, ds_name.templates))\n",
    "\n",
    "def create_prompted_dataset(datasets):\n",
    "    prompted_datasets = {}\n",
    "    for name, dataset in datasets.items():\n",
    "        prompted_dataset = dataset.map(lambda example: apply_template(example, dataset.templates, name))\n",
    "        # columns to keep\n",
    "        columns_to_keep = [\"prompt\", \"answer_choices\", \"dataset\"]\n",
    "        prompted_dataset = prompted_dataset.remove_columns([col for col in prompted_dataset.column_names if col not in columns_to_keep])\n",
    "        prompted_datasets[name] = prompted_dataset\n",
    "\n",
    "    prompted_datasets = concatenate_datasets([dataset for name, dataset in prompted_datasets.items()])\n",
    "    return prompted_datasets\n",
    "\n",
    "prompted_datasets = create_prompted_dataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prompted dataset\n",
    "\n",
    "# prompted_datasets.save_to_disk(\"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_0/dataset_test_with_answers.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in datasets.items():\n",
    "    print(name, dataset)\n",
    "    print(dataset.templates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incidental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
