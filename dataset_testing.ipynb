{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /local/home/antonis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /local/home/antonis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[dynet] random seed: 1234\n",
      "[dynet] allocating memory: 32MB\n",
      "[dynet] memory allocation done.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk, concatenate_datasets, get_dataset_config_names\n",
    "# from promptsource import templates\n",
    "import json\n",
    "import pickle\n",
    "import collections\n",
    "import pandas as pd\n",
    "from src.utils import concatenate_columns, count_gpt2_tokens\n",
    "from src.wimbd_ import _load_dataset\n",
    "\n",
    "CACHE_DIR = \"/share/edc/home/antonis/datasets/huggingface\"\n",
    "import os\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = CACHE_DIR\n",
    "\n",
    "# # Get a list of all supported datasets\n",
    "# datasets = templates.get_dataset_names()\n",
    "# print(datasets)\n",
    "\n",
    "# datasets = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/flan_v1/ds_c4_small\")\n",
    "# datasets = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/flan_v1/c4_mixed_Commonsense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "pth = \"/share/edc/home/antonis/LLM-Incidental-Supervision/wimbd/test_fixtures/c4-sample.00000-of-00001.json.gz\"\n",
    "# Open the file with gzip and read lines\n",
    "with gzip.open(pth, 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            # Try to parse each line as a separate JSON object\n",
    "            ds = json.loads(line)\n",
    "            # Process the ds as needed\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to decode line: {e}\")\n",
    "# ds = load_dataset(\"sciq\", cache_dir=CACHE_DIR)\n",
    "# ds = load_dataset(\"allenai/ai2_arc\", 'ARC-Easy', cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tulu = load_dataset(\"allenai/tulu-v2-sft-mixture\", cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'Question: Gdańsk (, ; German: \"\" , ) is a Polish city on the Baltic coast. It is the capital of the Pomeranian Voivodeship, Poland\\'s principal seaport and is also the centre of the country\\'s fourth-largest metropolitan area. \\n\\nThe city lies on the southern edge of Gdańsk Bay (of the Baltic Sea), in a conurbation with the city of Gdynia, spa town of Sopot, and suburban communities, which together form a metropolitan area called the Tricity (\"Trójmiasto\"), with a population approaching 1.4 million. Gdańsk itself has a population of 460,427 (December 2012), making it the largest city in the Pomerania region of Northern Poland. \\n\\nGdańsk is the capital of Gdańsk Pomerania and the largest city of Kashubia. With its origins as a Polish stronghold erected in the 980s by Mieszko I of Poland, the city\\'s history is complex, with periods of Polish rule, periods of Prussian or German rule, and periods of autonomy or self-rule as a \"free city\". Between the world wars, the Free City of Danzig was in a customs union with Poland and was located between German East Prussia and the so-called Polish Corridor. \\n\\nGdańsk lies at the mouth of the Motława River, connected to the Leniwka, a branch in the delta of the nearby Vistula River, which drains 60 percent of Poland and connects Gdańsk with the Polish capital, Warsaw. Together with the nearby port of Gdynia, Gdańsk is also an important industrial center. In the late Middle Ages it was an important seaport and shipbuilding town, and in the 14th and 15th centuries a member of the Hanseatic League. 1. Which bay is Gdansk on?\\n2. Which sea is that bay part of?\\n3. Is Gdansk a capital?\\n4. Of what?\\n5. Who was the first ruler?\\n6. Name one of the countries that has ruled it?\\n7. And another?\\n8. And one more?\\n9. Has it ever been under self-rule?\\n10. What was it called between the world wars?\\n11. Is it near a river?\\n12. Which one?\\n13. Which is connected to ? Provide a numbered list of answers.\\n****\\nA numbered of answers: 1. Gdańsk Bay\\n2. the Baltic Sea\\n3. Yes\\n4. Pomeranian Voivodeship\\n5. Mieszko I\\n6. Poland\\n7. German\\n8. Prussian\\n9. Yes\\n10. Danzig\\n11. Yes\\n12. the Motława River\\n13. the Leniwka\\nQ: Ferguson, Missouri (CNN) -- As the St. Louis suburb of Ferguson calmed Friday after nights of protests over the fatal shooting of an unarmed black teen, the question remains: Where\\'s the police officer who pulled the trigger? \\n\\nOfficer Darren Wilson, 28, shot Michael Brown on August 9. The shooting sparked days of violent protests in Ferguson as residents demanded his arrest. \\n\\nSeparate federal and local investigations are under way, and Wilson -- who has received death threats -- has disappeared from public view. \\n\\nGovernor orders drawdown of National Guard in Ferguson \\n\\nHere\\'s what is known about his whereabouts. \\n\\nWhere is he now? \\n\\nFew outside Wilson\\'s family and authorities know for sure. \\n\\nWilson owns a house in a modest neighborhood about 20 miles from Ferguson. He bought the house shortly after he was divorced last year, according to the St. Louis Post-Dispatch. \\n\\nBut several neighbors have told CNN that Wilson left home before his name was released last week. \\n\\nWhat are his neighbors saying about his whereabouts? \\n\\nNot much. Most have shunned reporters\\' requests for interviews, and some put signs in their yards shooing away journalists. \\n\\n\"We don\\'t know anything ... Pray for Peace,\" one read, according to the Post-Dispatch. \\n\\n\"We have 2 children. Do not knock!! No comment,\" another family wrote. \\n\\nAny trails on social media? \\n\\nThe newspaper reported that Wilson deactivated his social media accounts before his name went public. \\n\\nThe only social media presence for him now is from supporters, who have set up Facebook pages to support and raise money for him. \\n\\n1. unarmed black teen\\n2. Darren Wilson shot Michael Brown\\n3. Yes\\n4. Few outside Wilson\\'s family and authorities know for sure.\\n5. about 20 miles from Ferguson\\n6. No\\n7. Most have shunned reporters\\' requests for interviews, and some put signs in their yards shooing away journalists\\n8. federal and local investigations\\n9. 28\\n10. unknown\\n11. The shooting sparked days of violent protests\\n12. his arrest\\n13. Most have not\\n14. that Wilson left home\\n15. shortly after he was divorced\\n16. unknown\\n17. Yes\\n18. We have 2 children. Do not knock\\n19. no\\n20. Ferguson\\n\\nNumbered questions:\\n1. Who was Michael Brown?\\n2. What happened to him?\\n3. Was Darren Wilson a cop?\\n4. Where is Wilson now?\\n5. Where does he live?\\n6. Do his neighbors know where he is?\\n7. How have they handled the publicity?\\n8. What kind of ongoing investigations are there?\\n9. How old is Wilson?\\n10. Why did he shoot Michael Brown?\\n11. How did local people react to this?\\n12. What were they hoping to accomplish with the protests?\\n13. Have any of his neighbors spoken to press?\\n14. What did they tell CNN?\\n15. When did Wilson buy the house?\\n16. When was that?\\n17. Did he receive death threats?\\n18. What do the signs in the neighbors yards say?\\n19. Is Wilson active online?\\n20. What  town was Brown shot in?\\ninput: (CNN) -- At least one performer fell hard for Sunday night\\'s Billboard Music Awards. \\n\\nNot sure what that means? Well, check out the top five moments from Sunday night\\'s 2013 Billboard Music Awards: \\n\\n1. Miguel lands on a fan \\n\\nThe R & B singer accidentally landed on a woman in the mosh pit during a performance of his hit song \"Adorn.\" He was attempting a jump that went wrong. The fan appeared to be fine and the singer kept singing. Miguel later tweeted: \"got caught up in the moment, thank goodness Khyati is okay.\" \\n\\n2. Taylor Swift wins eight out of the 11 awards she was up for \\n\\nSwift is no stranger to taking to the stage to accept accolades, and on Sunday night she collected a few, including Billboard Artist of the Year. \\n\\n\"My album is kind of on the ends of the intense emotional spectrum,\" Swift said while accepting that award. \"You (fans) are the longest and best relationship I have ever had.\" \\n\\nShe also won Top Country Artist,Top Billboard 200 Artist, Top Female Artist, and Top Digital Songs Artist -- the last one a tie with singer Carly Rae Jepsen. Swift\\'s album \"Red\" won in the Top Billboard 200 and Country Album categories and her single \"We Are Never Ever Getting Back Together\" collected the trophy for Top Country Song. \\n\\n3. Justin Bieber gets booed \\n\\nWhile accepting the first ever Milestone Award, the Biebs was both cheered and jeered. He appeared to reference the rough times he has had of late in his acceptance speech.  1. Who was the one performer who fell hard?\\n2. was the fan ok?\\n3. how many awards Taylor Swift won?\\n4. Why did Justin get booed?\\n5. Who was Carly Rae Jepsen tied with ?\\n6. what song got top country song?\\n7. Was the fan female or male that Miguel fell on?\\n8. What did bieber talk about in his acceptance speech?\\n9. what swift\\'s ablum won the top billboard 200?\\n10. Was \"Adorn\" a hit song? Return numbered answers in your output.\\n\\noutput:'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tulu['train'][0]['messages'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '1. Miguel\\n2. Yes\\n3. Eight\\n4. unknown\\n5. Swift\\n6. \"We Are Never Ever Getting Back Together\"\\n7. Female\\n8. The rough times he has had of late.\\n9. \"Red\"\\n10. Yes'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tulu['train'][0]['messages'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'url', 'date'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "pth = \"/share/edc/home/antonis/LLM-Incidental-Supervision/wimbd/test_fixtures/c4-sample.00000-of-00001.json.gz\"\n",
    "# Open the file with gzip and read lines\n",
    "with gzip.open(pth, 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            # Try to parse each line as a separate JSON object\n",
    "            ds = json.loads(line)\n",
    "            # Process the ds as needed\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to decode line: {e}\")\n",
    "\n",
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset mmlu\n"
     ]
    }
   ],
   "source": [
    "ds_mmlu = _load_dataset(\"mmlu\", CACHE_DIR=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract_algebra': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'anatomy': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 135\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 14\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'astronomy': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 152\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 16\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'business_ethics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'clinical_knowledge': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 265\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 29\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'college_biology': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 144\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 16\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'college_chemistry': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 8\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'college_computer_science': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'college_mathematics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'college_medicine': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 173\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 22\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'college_physics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 102\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'computer_security': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'conceptual_physics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 235\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 26\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'econometrics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 114\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 12\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'electrical_engineering': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 145\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 16\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'elementary_mathematics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 378\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 41\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'formal_logic': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 126\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 14\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'global_facts': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 10\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_biology': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 310\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 32\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_chemistry': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 203\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 22\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_computer_science': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 9\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_european_history': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 165\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 18\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_geography': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 198\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 22\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_government_and_politics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 193\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 21\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_macroeconomics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 390\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 43\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_mathematics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 270\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 29\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_microeconomics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 238\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 26\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_physics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 151\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 17\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_psychology': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 545\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 60\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_statistics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 216\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 23\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_us_history': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 204\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 22\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'high_school_world_history': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 237\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 26\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'human_aging': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 223\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 23\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'human_sexuality': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 131\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 12\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'international_law': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 121\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 13\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'jurisprudence': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 108\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'logical_fallacies': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 163\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 18\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'machine_learning': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 112\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'management': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 103\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'marketing': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 234\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 25\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'medical_genetics': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'miscellaneous': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 783\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 86\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'moral_disputes': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 346\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 38\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'moral_scenarios': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 895\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'nutrition': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 306\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 33\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'philosophy': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 311\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 34\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'prehistory': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 324\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 35\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'professional_accounting': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 282\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 31\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'professional_law': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 1534\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 170\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'professional_medicine': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 272\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 31\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'professional_psychology': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 612\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 69\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'public_relations': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 110\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 12\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'security_studies': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 245\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 27\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'sociology': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 201\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 22\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'us_foreign_policy': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 11\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'virology': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 166\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 18\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " }),\n",
       " 'world_religions': DatasetDict({\n",
       "     auxiliary_train: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 99842\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 171\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 19\n",
       "     })\n",
       "     dev: Dataset({\n",
       "         features: ['question', 'choices', 'answer'],\n",
       "         num_rows: 5\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_mmlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_['question'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[181, 40, 64, 85, 166]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144938185\n",
      "abstract_algebra auxiliary_train 1451.6754972857113\n",
      "12377\n",
      "abstract_algebra test 123.77\n",
      "1367\n",
      "abstract_algebra validation 124.27272727272727\n",
      "516\n",
      "abstract_algebra dev 103.2\n",
      "144938185\n",
      "anatomy auxiliary_train 1451.6754972857113\n",
      "11117\n",
      "anatomy test 82.34814814814816\n",
      "972\n",
      "anatomy validation 69.42857142857143\n",
      "261\n",
      "anatomy dev 52.2\n",
      "144938185\n",
      "astronomy auxiliary_train 1451.6754972857113\n",
      "13075\n",
      "astronomy test 86.01973684210526\n",
      "1330\n",
      "astronomy validation 83.125\n",
      "424\n",
      "astronomy dev 84.8\n",
      "144938185\n",
      "business_ethics auxiliary_train 1451.6754972857113\n",
      "15777\n",
      "business_ethics test 157.77\n",
      "1297\n",
      "business_ethics validation 117.9090909090909\n",
      "1087\n",
      "business_ethics dev 217.4\n",
      "144938185\n",
      "clinical_knowledge auxiliary_train 1451.6754972857113\n",
      "17581\n",
      "clinical_knowledge test 66.3433962264151\n",
      "1870\n",
      "clinical_knowledge validation 64.48275862068965\n",
      "413\n",
      "clinical_knowledge dev 82.6\n",
      "144938185\n",
      "college_biology auxiliary_train 1451.6754972857113\n",
      "19858\n",
      "college_biology test 137.90277777777777\n",
      "2057\n",
      "college_biology validation 128.5625\n",
      "750\n",
      "college_biology dev 150.0\n",
      "144938185\n",
      "college_chemistry auxiliary_train 1451.6754972857113\n",
      "13117\n",
      "college_chemistry test 131.17\n",
      "866\n",
      "college_chemistry validation 108.25\n",
      "669\n",
      "college_chemistry dev 133.8\n",
      "144938185\n",
      "college_computer_science auxiliary_train 1451.6754972857113\n",
      "28850\n",
      "college_computer_science test 288.5\n",
      "2267\n",
      "college_computer_science validation 206.0909090909091\n",
      "2453\n",
      "college_computer_science dev 490.6\n",
      "144938185\n",
      "college_mathematics auxiliary_train 1451.6754972857113\n",
      "16704\n",
      "college_mathematics test 167.04\n",
      "1851\n",
      "college_mathematics validation 168.27272727272728\n",
      "1178\n",
      "college_mathematics dev 235.6\n",
      "144938185\n",
      "college_medicine auxiliary_train 1451.6754972857113\n",
      "52823\n",
      "college_medicine test 305.33526011560696\n",
      "4188\n",
      "college_medicine validation 190.36363636363637\n",
      "601\n",
      "college_medicine dev 120.2\n",
      "144938185\n",
      "college_physics auxiliary_train 1451.6754972857113\n",
      "20200\n",
      "college_physics test 198.0392156862745\n",
      "2581\n",
      "college_physics validation 234.63636363636363\n",
      "1107\n",
      "college_physics dev 221.4\n",
      "144938185\n",
      "computer_security auxiliary_train 1451.6754972857113\n",
      "11809\n",
      "computer_security test 118.09\n",
      "2866\n",
      "computer_security validation 260.54545454545456\n",
      "354\n",
      "computer_security dev 70.8\n",
      "144938185\n",
      "conceptual_physics auxiliary_train 1451.6754972857113\n",
      "17888\n",
      "conceptual_physics test 76.11914893617022\n",
      "1689\n",
      "conceptual_physics validation 64.96153846153847\n",
      "481\n",
      "conceptual_physics dev 96.2\n",
      "144938185\n",
      "econometrics auxiliary_train 1451.6754972857113\n",
      "23745\n",
      "econometrics test 208.28947368421052\n",
      "2164\n",
      "econometrics validation 180.33333333333334\n",
      "1182\n",
      "econometrics dev 236.4\n",
      "144938185\n",
      "electrical_engineering auxiliary_train 1451.6754972857113\n",
      "10839\n",
      "electrical_engineering test 74.75172413793103\n",
      "1277\n",
      "electrical_engineering validation 79.8125\n",
      "681\n",
      "electrical_engineering dev 136.2\n",
      "144938185\n",
      "elementary_mathematics auxiliary_train 1451.6754972857113\n",
      "42789\n",
      "elementary_mathematics test 113.1984126984127\n",
      "5343\n",
      "elementary_mathematics validation 130.3170731707317\n",
      "713\n",
      "elementary_mathematics dev 142.6\n",
      "144938185\n",
      "formal_logic auxiliary_train 1451.6754972857113\n",
      "25919\n",
      "formal_logic test 205.70634920634922\n",
      "3298\n",
      "formal_logic validation 235.57142857142858\n",
      "804\n",
      "formal_logic dev 160.8\n",
      "144938185\n",
      "global_facts auxiliary_train 1451.6754972857113\n",
      "11223\n",
      "global_facts test 112.23\n",
      "988\n",
      "global_facts validation 98.8\n",
      "518\n",
      "global_facts dev 103.6\n",
      "144938185\n",
      "high_school_biology auxiliary_train 1451.6754972857113\n",
      "45774\n",
      "high_school_biology test 147.65806451612903\n",
      "4614\n",
      "high_school_biology validation 144.1875\n",
      "674\n",
      "high_school_biology dev 134.8\n",
      "144938185\n",
      "high_school_chemistry auxiliary_train 1451.6754972857113\n",
      "26267\n",
      "high_school_chemistry test 129.39408866995075\n",
      "3153\n",
      "high_school_chemistry validation 143.3181818181818\n",
      "814\n",
      "high_school_chemistry dev 162.8\n",
      "144938185\n",
      "high_school_computer_science auxiliary_train 1451.6754972857113\n",
      "22341\n",
      "high_school_computer_science test 223.41\n",
      "1220\n",
      "high_school_computer_science validation 135.55555555555554\n",
      "1424\n",
      "high_school_computer_science dev 284.8\n",
      "144938185\n",
      "high_school_european_history auxiliary_train 1451.6754972857113\n",
      "229515\n",
      "high_school_european_history test 1391.0\n",
      "24850\n",
      "high_school_european_history validation 1380.5555555555557\n",
      "9881\n",
      "high_school_european_history dev 1976.2\n",
      "144938185\n",
      "high_school_geography auxiliary_train 1451.6754972857113\n",
      "17034\n",
      "high_school_geography test 86.03030303030303\n",
      "2073\n",
      "high_school_geography validation 94.22727272727273\n",
      "448\n",
      "high_school_geography dev 89.6\n",
      "144938185\n",
      "high_school_government_and_politics auxiliary_train 1451.6754972857113\n",
      "18638\n",
      "high_school_government_and_politics test 96.56994818652849\n",
      "2156\n",
      "high_school_government_and_politics validation 102.66666666666667\n",
      "473\n",
      "high_school_government_and_politics dev 94.6\n",
      "144938185\n",
      "high_school_macroeconomics auxiliary_train 1451.6754972857113\n",
      "37604\n",
      "high_school_macroeconomics test 96.42051282051283\n",
      "4329\n",
      "high_school_macroeconomics validation 100.67441860465117\n",
      "297\n",
      "high_school_macroeconomics dev 59.4\n",
      "144938185\n",
      "high_school_mathematics auxiliary_train 1451.6754972857113\n",
      "40427\n",
      "high_school_mathematics test 149.72962962962964\n",
      "4225\n",
      "high_school_mathematics validation 145.68965517241378\n",
      "1018\n",
      "high_school_mathematics dev 203.6\n",
      "144938185\n",
      "high_school_microeconomics auxiliary_train 1451.6754972857113\n",
      "23932\n",
      "high_school_microeconomics test 100.5546218487395\n",
      "2675\n",
      "high_school_microeconomics validation 102.88461538461539\n",
      "351\n",
      "high_school_microeconomics dev 70.2\n",
      "144938185\n",
      "high_school_physics auxiliary_train 1451.6754972857113\n",
      "30489\n",
      "high_school_physics test 201.91390728476821\n",
      "3791\n",
      "high_school_physics validation 223.0\n",
      "923\n",
      "high_school_physics dev 184.6\n",
      "144938185\n",
      "high_school_psychology auxiliary_train 1451.6754972857113\n",
      "75089\n",
      "high_school_psychology test 137.77798165137614\n",
      "8570\n",
      "high_school_psychology validation 142.83333333333334\n",
      "852\n",
      "high_school_psychology dev 170.4\n",
      "144938185\n",
      "high_school_statistics auxiliary_train 1451.6754972857113\n",
      "57573\n",
      "high_school_statistics test 266.5416666666667\n",
      "5423\n",
      "high_school_statistics validation 235.7826086956522\n",
      "1343\n",
      "high_school_statistics dev 268.6\n",
      "144938185\n",
      "high_school_us_history auxiliary_train 1451.6754972857113\n",
      "245706\n",
      "high_school_us_history test 1204.4411764705883\n",
      "26701\n",
      "high_school_us_history validation 1213.6818181818182\n",
      "7850\n",
      "high_school_us_history dev 1570.0\n",
      "144938185\n",
      "high_school_world_history auxiliary_train 1451.6754972857113\n",
      "318052\n",
      "high_school_world_history test 1341.9915611814347\n",
      "39074\n",
      "high_school_world_history validation 1502.8461538461538\n",
      "3975\n",
      "high_school_world_history dev 795.0\n",
      "144938185\n",
      "human_aging auxiliary_train 1451.6754972857113\n",
      "17329\n",
      "human_aging test 77.7085201793722\n",
      "1700\n",
      "human_aging validation 73.91304347826087\n",
      "485\n",
      "human_aging dev 97.0\n",
      "144938185\n",
      "human_sexuality auxiliary_train 1451.6754972857113\n",
      "13432\n",
      "human_sexuality test 102.53435114503817\n",
      "997\n",
      "human_sexuality validation 83.08333333333333\n",
      "437\n",
      "human_sexuality dev 87.4\n",
      "144938185\n",
      "international_law auxiliary_train 1451.6754972857113\n",
      "8500\n",
      "international_law test 70.24793388429752\n",
      "930\n",
      "international_law validation 71.53846153846153\n",
      "337\n",
      "international_law dev 67.4\n",
      "144938185\n",
      "jurisprudence auxiliary_train 1451.6754972857113\n",
      "11814\n",
      "jurisprudence test 109.38888888888889\n",
      "1370\n",
      "jurisprudence validation 124.54545454545455\n",
      "514\n",
      "jurisprudence dev 102.8\n",
      "144938185\n",
      "logical_fallacies auxiliary_train 1451.6754972857113\n",
      "16819\n",
      "logical_fallacies test 103.1840490797546\n",
      "1611\n",
      "logical_fallacies validation 89.5\n",
      "536\n",
      "logical_fallacies dev 107.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m ds[task]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      5\u001b[0m     ds_ \u001b[38;5;241m=\u001b[39m ds[task][split]\n\u001b[0;32m----> 6\u001b[0m     question_lengths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(question) \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m \u001b[43mds_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(question_lengths))\n\u001b[1;32m      8\u001b[0m     avg_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(question_lengths) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(question_lengths) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(question_lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/incidental/lib/python3.11/site-packages/datasets/arrow_dataset.py:2803\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/incidental/lib/python3.11/site-packages/datasets/arrow_dataset.py:2788\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2786\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2787\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2788\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2790\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.conda/envs/incidental/lib/python3.11/site-packages/datasets/formatting/formatting.py:629\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    627\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/.conda/envs/incidental/lib/python3.11/site-packages/datasets/formatting/formatting.py:398\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_batch(pa_table)\n",
      "File \u001b[0;32m~/.conda/envs/incidental/lib/python3.11/site-packages/datasets/formatting/formatting.py:441\u001b[0m, in \u001b[0;36mPythonFormatter.format_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 441\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_column(column, pa_table\u001b[38;5;241m.\u001b[39mcolumn_names[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "File \u001b[0;32m~/.conda/envs/incidental/lib/python3.11/site-packages/datasets/formatting/formatting.py:147\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto_pylist()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get avg length of questions for different splits\n",
    "\n",
    "for task in ds.keys():\n",
    "    for split in ds[task].keys():\n",
    "        ds_ = ds[task][split]\n",
    "        question_lengths = [len(question) for question in ds_['question']]\n",
    "        avg_length = sum(question_lengths) / len(question_lengths) if len(question_lengths) > 0 else 0\n",
    "        print(task, split, avg_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"./results/n-grams/wmt/pile/exp4/n_samples_None_fkeyFalse_rkeyFalse_fstopTrue_onlyalphaTrue/7/all/es-en.pkl\"\n",
    "df = pd.DataFrame(pickle.load(open(pth, \"rb\"))).T.sort_values(\"value\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().rename(columns={'index': 'ngram'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "\n",
    "# choose only rows were ngram column has more 7 or more ngrams\n",
    "\n",
    "df = df[df[\"ngram\"].apply(lambda x: len(x.split()) >= 5)]\n",
    "df = df[df[\"value\"] > 0].reset_index(drop=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# europarl = load_dataset(\"wmt/europarl\", cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt14 = load_dataset(\"wmt14\", 'cs-en', cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt09 = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/wmt09_gens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt09['en-hu']['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt09['en-hu']['translation'][0]['gen'] = 1\n",
    "wmt_dict = wmt09['en-hu'].to_dict()\n",
    "wmt_dict['translation'][0]['gen'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_dict['translation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens = [1] * len(wmt09['en-hu']['translation'])\n",
    "wmt09['en-hu']['translation']['gen'] = gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(wmt09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wmt_09 = _load_dataset(\"wmt\")\n",
    "trivia_qa_ngram_pth = \"/share/edc/home/antonis/LLM-Incidental-Supervision/incidental-supervision/results/n-grams/trivia_qa/pile/exp_3/test-set/n_samples_None_fkeyFalse_rkeyFalse_fstopTrue_onlyalphaFalse/5/all/trivia_qa.pkl\"\n",
    "trivia_qa = pd.DataFrame(pd.read_pickle(trivia_qa_ngram_pth)).T.sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance_pth = \"./results/n-grams/wmt/pile/exp4/n_samples_None_fkeyFalse_rkeyFalse_fstopTrue_onlyalphaTrue/2/model_instance_results_0-shot_common.pkl\"\n",
    "with open(model_instance_pth, \"rb\") as f:\n",
    "    model_instance = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_res_pth = \"./results/n-grams/wmt/pile/exp4/n_samples_None_fkeyFalse_rkeyFalse_fstopTrue_onlyalphaTrue/2/examples_dfs_0-shot_common_models.pkl\"\n",
    "with open(wmt_res_pth, \"rb\") as f:\n",
    "    wmt_res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_qa = load_dataset(\"trivia_qa\", \"unfiltered.nocontext\", cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_qa['test'][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_qa['validation'][1]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_qa['test'][1]\n",
    "\n",
    "# print 10 question answer pairs from test set\n",
    "\n",
    "for i in range(10):\n",
    "    print(trivia_qa['test'][i]['question'])\n",
    "    print(trivia_qa['test'][i]['answer'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_qa['test'][1]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivia_qa['test'][1]['search_results'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bigbench_tasks = ['bigbench_causal_judgement', 'bigbench_date_understanding', 'bigbench_disambiguation_qa', 'bigbench_dyck_languages', 'bigbench_formal_fallacies_syllogisms_negation', 'bigbench_geometric_shapes', 'bigbench_hyperbaton', 'bigbench_logical_deduction_five_objects', 'bigbench_logical_deduction_seven_objects', 'bigbench_logical_deduction_three_objects', 'bigbench_movie_recommendation', 'bigbench_navigate', 'bigbench_reasoning_about_colored_objects', 'bigbench_ruin_names', 'bigbench_salient_translation_error_detection', 'bigbench_snarks', 'bigbench_sports_understanding', 'bigbench_temporal_sequences', 'bigbench_tracking_shuffled_objects_five_objects', 'bigbench_tracking_shuffled_objects_seven_objects', 'bigbench_tracking_shuffled_objects_three_objects', 'blimp_adjunct_island']\n",
    "# # save bigbench tasks as txt\n",
    "# path = \"/share/edc/home/antonis/LLM-Incidental-Supervision/incidental-supervision/configs\"\n",
    "# with open(os.path.join(path, \"bigbench_tasks.txt\"), \"w\") as f:\n",
    "#     for task in bigbench_tasks:\n",
    "#         f.write(task + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = get_dataset_config_names(\"hendrycks_test\")\n",
    "\n",
    "ds_full = {}\n",
    "for config in configs:\n",
    "    ds_full[config] = load_dataset(\"hendrycks_test\", config, cache_dir=CACHE_DIR)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full['abstract_algebra']['test']['choices'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bigbench tasks\n",
    "bigbench_tasks = []\n",
    "with open(\"./configs/data/bigbench_tasks.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        bigbench_tasks.append(line.strip())\n",
    "bigbench_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = get_dataset_config_names(\"bigbench\")\n",
    "configs\n",
    "\n",
    "ds_full = {}\n",
    "for config in configs:\n",
    "    if config in bigbench_tasks:\n",
    "        ds_full[config] = load_dataset(\"bigbench\", config, \n",
    "                                       cache_dir=CACHE_DIR,\n",
    "                                       trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_logical = load_dataset(\"bigbench\", \"logical_deduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, ds in ds_full.items():\n",
    "    print(name, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = ds_full['abstract_algebra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1_concat = concatenate_datasets([ds for ds in ds_1.values()])\n",
    "ds_1_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full['abstract_algebra']['auxiliary_train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_full['abstract_algebra']['test'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "example = ds[15]['answer']\n",
    "print(str(example))\n",
    "\n",
    "text_gram = ngrams(\"hello\", 5)\n",
    "\n",
    "print(list(text_gram))\n",
    "\n",
    "text_gram = [''.join(ngram) for ngram in text_gram]\n",
    "\n",
    "print(text_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ds_full.keys():\n",
    "    ds = ds_full[key]['test']\n",
    "    print(key, ds)\n",
    "    print(ds[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_pair = \"es-en\"\n",
    "dataset_name = \"wmt-14\"\n",
    "\n",
    "datasets = load_dataset(\"tasksource/mmlu\", cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset(\"SirNeural/flan_v2\", cache_dir=CACHE_DIR)\n",
    "ds_task = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/flan_v1_task_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"EleutherAI/the_pile_deduplicated\"\n",
    "corpus_path = f\"/share/edc/home/antonis/datasets/huggingface/flan_v1/ds_{corpus}_small\"\n",
    "# ds = load_from_disk(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_task['NLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "task_keys = list(ds_task.keys())\n",
    "n_index = random.randint(0, len(task_keys))\n",
    "task = ds_task[task_keys[n_index]]\n",
    "n_index_2 = random.randint(0, len(task))\n",
    "\n",
    "print(task[n_index_2][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_examples = collections.defaultdict(lambda: collections.defaultdict(dict))\n",
    "for task in task_ds.keys():\n",
    "    task_dataset = task_ds[task]\n",
    "    # sample 10 examples\n",
    "    task_dataset = task_dataset.shuffle(seed=42).select(range(20))\n",
    "    for n, example in enumerate(task_dataset):\n",
    "        task_examples[task][n]['inputs'] = example['inputs']\n",
    "        task_examples[task][n]['targets'] = example['targets']\n",
    "\n",
    "# save task_examples as jsonl\n",
    "with open(\"/share/edc/home/antonis/datasets/huggingface/flan_v1_task_examples.jsonl\", \"w\") as f:\n",
    "    for task in task_examples.keys():\n",
    "        for n, example in task_examples[task].items():\n",
    "            # Create a new dictionary for each line, with 'task', 'example_number' and 'text' keys\n",
    "            line = {'task': task, 'example_number': n, 'text': example}\n",
    "            f.write(json.dumps(line, indent=4) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 20% of c4\n",
    "c4 = load_dataset(\"c4\", \"en\", split=\"train[:20%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "\n",
    "max_len = 1000\n",
    "n_groups = 10\n",
    "model_name_or_path = \"/share/edc/home/antonis/LLM-Incidental-Supervision/incidental-supervision/models/pythia/experiment_1/huggingface/flan_v1/c4_mixed_Commonsense/EleutherAI/pythia-1.4B-deduped_ckpt_False/checkpoint-70000\"\n",
    "task_samples_path = f\"/share/edc/home/antonis/datasets/huggingface/flan_v1/task_ds_sampled_{max_len}_{n_groups}.pkl\"\n",
    "dataset_dict_path = f\"/share/edc/home/antonis/datasets/huggingface/flan_v1/ds_c4_small_sampled_{max_len}_{n_groups}\"\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "with open(task_samples_path, 'rb') as f:\n",
    "    task_samples_dict = collections.defaultdict(dict, pickle.load(f))\n",
    "\n",
    "ds = load_from_disk(dataset_dict_path)\n",
    "\n",
    "grad_pth = \"/share/edc/home/antonis/LLM-Incidental-Supervision/incidental-supervision/grads_c4.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(grad_pth, 'rb') as f:\n",
    "    grads = pickle.load(f)\n",
    "\n",
    "grads.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grads['0'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "gradient_mags = gradient_mags = [torch.norm(grad[0]).item() for grad in grads['0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Specify the directory containing your dataset files\n",
    "dataset_dir = \"/share/edc/home/antonis/datasets/huggingface/flan_v1/c4_mixed_QA_NLI_Summarization_Commonsense\"\n",
    "\n",
    "# Create subdirectories for each cache type\n",
    "cache_types = [\"0e1ee472afc16a84\", \"93decdfdc22cb71c\", \"a516fcb03f1e5f67\", \"cc79b545cdc85cd7\"]\n",
    "for cache_type in cache_types:\n",
    "    os.makedirs(os.path.join(dataset_dir, cache_type), exist_ok=True)\n",
    "\n",
    "# Move each file to the appropriate subdirectory\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    for cache_type in cache_types:\n",
    "        if filename.startswith(f\"cache-{cache_type}\"):\n",
    "            shutil.move(os.path.join(dataset_dir, filename), os.path.join(dataset_dir, cache_type, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Specify the directory containing your dataset files\n",
    "dataset_dir = \"/share/edc/home/antonis/datasets/huggingface/flan_v1/c4_mixed_QA_NLI_Summarization_Commonsense\"\n",
    "\n",
    "# Specify the cache types\n",
    "cache_types = [\"0e1ee472afc16a84\", \"93decdfdc22cb71c\", \"a516fcb03f1e5f67\", \"cc79b545cdc85cd7\"]\n",
    "\n",
    "# Move each file back to the original directory\n",
    "for cache_type in cache_types:\n",
    "    cache_dir = os.path.join(dataset_dir, cache_type)\n",
    "    for filename in os.listdir(cache_dir):\n",
    "        shutil.move(os.path.join(cache_dir, filename), os.path.join(dataset_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = os.path.join(dataset_dir, cache_types[0])\n",
    "\n",
    "cache_ds = load_from_disk(cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(example):\n",
    "    for key in example.keys():\n",
    "        print(f\"{key}: {example[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset(\"conceptofmind/dialog_submix_original\", split=\"train\")\n",
    "# ds = load_dataset(\"conceptofmind/cot_submix_original\", split=\"train\")\n",
    "ds = load_dataset(\"conceptofmind/flan2021_submix_original\", split=\"train\", cache_dir=CACHE_DIR)\n",
    "# ds = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/flan_v1/c4_mixed_NLI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_task = load_from_disk('/share/edc/home/antonis/datasets/huggingface/flan_v1_task_ds')\n",
    "ds_c4_small = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/flan_v1/ds_c4_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds = ds_task['NLI'].filter(lambda example: 'anli/r2' in example['task_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds['inputs'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentiment_ds = ds_task['Sentiment']\n",
    "\n",
    "n_samples = 20\n",
    "n_iter = 0\n",
    "while n_iter < n_samples:\n",
    "    index = random.randint(0, len(sentiment_ds) - 1)\n",
    "    row = sentiment_ds[index]\n",
    "    if row['task_name'] == 'glue/sst2:2.0.0':\n",
    "        print(f\"------ inputs: {row['inputs']}\")\n",
    "        print(f\"targets: {row['targets']}\")\n",
    "        n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_t0 = load_dataset(\"conceptofmind/t0_submix_original\", cache_dir=CACHE_DIR, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_t0 = concatenate_columns(ds_t0, 'inputs', 'targets', 'text')\n",
    "# count_gpt2_tokens(ds_t0, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cot = load_dataset(\"conceptofmind/cot_submix_original\", cache_dir=CACHE_DIR, split=\"train\")\n",
    "ds_cot = concatenate_columns(ds_cot, 'inputs', 'targets', 'text')\n",
    "n_cot_tokens = count_gpt2_tokens(ds_cot, 'text')\n",
    "print(f\"{n_cot_tokens:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{n_cot_tokens:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_dict = {}\n",
    "for key in ds_task:\n",
    "    unique_targets = ds_task[key].unique('targets')\n",
    "    short_targets = [target for target in unique_targets if len(target) < 20]\n",
    "    targets_dict[key] = short_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/share/edc/home/antonis/datasets/huggingface/flan_v1_task_ds/short_targets.json', 'w') as f:\n",
    "    json.dump(targets_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "with open('/share/edc/home/antonis/datasets/huggingface/flan_v1_task_ds/short_targets.json', 'r') as f:\n",
    "    targets_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is str in list\n",
    "\n",
    "strings = [\"it is not possible to tell\", \"pick from the following\"]\n",
    "task = \"NLI\"\n",
    "for string in strings:\n",
    "    if string in targets_dict[task]:\n",
    "        print(f\"{string} in {task}\")\n",
    "    else:\n",
    "        print(f\"{string} not in {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_flan = load_dataset(\"declare-lab/flan-mini\", subset=\"Flan2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_options(input_string):\n",
    "    # Define a regular expression pattern for the options phrase\n",
    "    pattern = r\"(options are|OPTIONS|options):?\\s*(.*)\"\n",
    "    # Search for the pattern in the input string, ignoring case\n",
    "    match = re.search(pattern, input_string, re.IGNORECASE)\n",
    "    if match:\n",
    "        # If a match is found, split the matched string on '--' to get individual options\n",
    "        options = match.group(2).split('--')\n",
    "        # Remove leading and trailing whitespace from each option\n",
    "        options = [option.strip() for option in options if option]\n",
    "        return options\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "print(extract_options(ds_task['NLI']['inputs'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ds['task_name']))\n",
    "set(ds['task_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_tasks = [\n",
    "    \"anli\",\n",
    "    \"rte\",\n",
    "    \"cb\",\n",
    "    \"snli\",\n",
    "    \"mnli\",\n",
    "    \"wnli\",\n",
    "    \"qnli\"\n",
    "]\n",
    "\n",
    "ds1 = ds.filter(lambda example: any(task in example['task_name'] for task in required_tasks))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_columns(dataset, column1, column2, new_column_name):\n",
    "    def concat_example(example):\n",
    "        example[new_column_name] = example[column1] + \" \" + example[column2]\n",
    "        return example\n",
    "\n",
    "    return dataset.map(concat_example)\n",
    "\n",
    "# Usage example:\n",
    "ds1 = concatenate_columns(ds1, 'inputs', 'targets', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def total_tokens(dataset, text_field):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    total_count = 0\n",
    "    \n",
    "    for example in tqdm(dataset, desc=\"Counting tokens\"):\n",
    "        text = example[text_field]\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        total_count += len(tokens)\n",
    "\n",
    "    # Print the total count in scientific notation\n",
    "    print(f\"Total number of tokens: {total_count:.2e}\")\n",
    "\n",
    "    return total_count\n",
    "\n",
    "# Usage example:\n",
    "total_count = total_tokens(ds1, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of tokens: {total_count:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds['label']\n",
    "\n",
    "# # get unique labels\n",
    "# labels = set(ds['label'])\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"/share/edc/home/antonis/datasets/huggingface/merged_datasets/NLI/P_1_PQA_5_promptsource_False/dataset_1/dataset_train.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ds['train']['label']\n",
    "\n",
    "# find -1 in labels\n",
    "non_matching = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == -1:\n",
    "        print(i)\n",
    "        non_matching.append(i)\n",
    "        print_example(ds['train'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search revursively for .arrow file\n",
    "import glob\n",
    "import json\n",
    "\n",
    "base_dir = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_unified_labels/P_1_PQA_5_promptsource_False\"\n",
    "\n",
    "arrow_files = glob.glob(base_dir + \"/**/*.arrow\", recursive=False)\n",
    "print(arrow_files)\n",
    "\n",
    "for file_ in arrow_files:\n",
    "    print(file_)\n",
    "    ds = load_from_disk(file_)\n",
    "    print(ds)\n",
    "\n",
    "json_files = glob.glob(base_dir + \"/**/*.json\", recursive=False)\n",
    "print(json_files)\n",
    "\n",
    "\n",
    "# def print_keys_values(data):\n",
    "#     for key, value in data.items():\n",
    "#         print(key)\n",
    "#         if isinstance(value, dict):\n",
    "#             print_keys_values(value)\n",
    "#         else:\n",
    "#             print(value)\n",
    "\n",
    "for file_ in json_files:\n",
    "    print(file_)\n",
    "    with open(file_, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # print keys and values recursively\n",
    "    # print_keys_values(data)\n",
    "    print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_pth = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/dataset_1/dataset_train.arrow\"\n",
    "# ds_pth = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment/dataset_1/dataset_validation.arrow\"\n",
    "# ds_pth = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment/P_QA_5/dataset_1/dataset_validation.arrow\"\n",
    "# dataset_c4 = load_dataset(\"c4\", \"en\", split=\"train[:20%]\", cache_dir=CACHE_DIR)\n",
    "\n",
    "ds_pth = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_1/dataset_train.arrow\"\n",
    "dataset = load_from_disk(ds_pth)\n",
    "\n",
    "# ds_path2 = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_0/dataset_train.arrow\"\n",
    "# dataset2 = load_from_disk(ds_path2)\n",
    "\n",
    "ds_pth_validation = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_1/dataset_validation.arrow\"\n",
    "dataset_validation = load_from_disk(ds_pth_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_imdb = load_dataset(\"imdb\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "ds_sst = load_dataset(\"sst\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "\n",
    "print(f\"IMDB len: {len(ds_imdb)}\")\n",
    "print(f\"SST len: {len(ds_sst)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first protion is IMDB, second is SST\n",
    "ds_pth_val = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_1/dataset_validation.arrow\"\n",
    "dataset_val = load_from_disk(ds_pth_val)\n",
    "ds_pth2_val = \"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_0/dataset_validation.arrow\"\n",
    "dataset2_val = load_from_disk(ds_pth2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ds_path = \"/share/edc/home/antonis/datasets/huggingface/C4/limit_total_tokens_1240000000/train\"\n",
    "ds = load_from_disk(ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train1: {len(dataset)}\")\n",
    "print(f\"train2: {len(dataset2)}\")\n",
    "print(f\"val1: {len(dataset_val)}\")\n",
    "print(f\"val2: {len(dataset2_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val.select(range(len(dataset2_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val[-len(dataset2_val):]\n",
    "\n",
    "dataset_val1 = dataset_val.select(range(len(ds_imdb)))\n",
    "dataset_val2 = dataset_val.select(range(len(ds_imdb), len(dataset_val)))\n",
    "\n",
    "assert len(dataset_val1) + len(dataset_val2) == len(dataset_val), f\"len mismatch: {len(dataset_val1)} + {len(dataset_val2)} != {len(dataset_val)}\"\n",
    "\n",
    "def add_new_column1(example, keyword, column_name=\"dataset\"):\n",
    "    example[column_name] = keyword\n",
    "    return example\n",
    "\n",
    "dataset_val1 = dataset_val1.map(lambda x: add_new_column1(x, \"imdb\"))\n",
    "dataset_val2 = dataset_val2.map(lambda x: add_new_column1(x, \"sst\"))\n",
    "\n",
    "dataset_val = concatenate_datasets([dataset_val1, dataset_val2])\n",
    "\n",
    "# save the new dataset\n",
    "dataset_val.save_to_disk(os.path.join(os.path.dirname(ds_pth_val), \"dataset_validation_wname.arrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(os.path.dirname(ds_pth_val), \"dataset_validation_wname.arrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from datasets import load_dataset, Dataset\n",
    "from promptsource.templates import DatasetTemplates, TemplateCollection\n",
    "# set logging level to INFO\n",
    "from src._promptsource import get_T0MixtureDatasets \n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOMixture = [\n",
    "    (\"sst\",\"default\"), # Senitment Classification\")\n",
    "    (\"imdb\",None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = get_T0MixtureDatasets(\"test\", max_samples=1000, return_as_dict=True)\n",
    "# ds_sst = load_dataset(\"sst\", \"default\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "ds_imdb = load_dataset(\"imdb\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "# ds_yelp_review = load_dataset(\"yelp_review_full\", split=\"train\", cache_dir=CACHE_DIR)\n",
    "ds_sentiment140 = load_dataset(\"sentiment140\", split=\"test\", cache_dir=CACHE_DIR)\n",
    "\n",
    "print(f\"IMDB len: {len(ds_imdb)}\")\n",
    "# print(f\"Yelp len: {len(ds_yelp_review)}\")\n",
    "print(f\"Sentiment140 len: {len(ds_sentiment140)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, subset = TOMixture[0]\n",
    "example = ds_sst.select(range(1))\n",
    "# DatasetTemplates(name, subset).templates.get_get_answer_choices_list(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds_sst))\n",
    "print(len(ds_imdb))\n",
    "# print(len(ds_yelp_review))\n",
    "# print(len(ds_sentiment140))\n",
    "\n",
    "import random\n",
    "\n",
    "ds_name = datasets['imdb']\n",
    "\n",
    "def apply_template(example, template, dataset_name):\n",
    "    if isinstance(template, list):\n",
    "        template = random.choice(template)\n",
    "    try:\n",
    "        answer_choices = template.get_answer_choices_list(example)\n",
    "    except:\n",
    "        answer_choices = None\n",
    "    # example['label'] = float(example['label'])\n",
    "    return {\"prompt\": template.apply(example), \"answer_choices\": answer_choices, \"dataset\": dataset_name}\n",
    "\n",
    "# # You can apply the template to the dataset\n",
    "# prompted_dataset = ds_name.map(lambda example: apply_template(example, ds_name.templates))\n",
    "\n",
    "def create_prompted_dataset(datasets):\n",
    "    prompted_datasets = {}\n",
    "    for name, dataset in datasets.items():\n",
    "        prompted_dataset = dataset.map(lambda example: apply_template(example, dataset.templates, name))\n",
    "        # columns to keep\n",
    "        columns_to_keep = [\"prompt\", \"answer_choices\", \"dataset\"]\n",
    "        prompted_dataset = prompted_dataset.remove_columns([col for col in prompted_dataset.column_names if col not in columns_to_keep])\n",
    "        prompted_datasets[name] = prompted_dataset\n",
    "\n",
    "    prompted_datasets = concatenate_datasets([dataset for name, dataset in prompted_datasets.items()])\n",
    "    return prompted_datasets\n",
    "\n",
    "prompted_datasets = create_prompted_dataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prompted dataset\n",
    "\n",
    "# prompted_datasets.save_to_disk(\"/share/edc/home/antonis/datasets/huggingface/merged_datasets/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_0/dataset_test_with_answers.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in datasets.items():\n",
    "    print(name, dataset)\n",
    "    print(dataset.templates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incidental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
