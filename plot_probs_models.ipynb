{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from src.wimbd_ import BasePaths as PATHS\n",
    "from src.wimbd_ import DataConfigs as CONFIG\n",
    "from src.wimbd_ import post_filter\n",
    "from src.utils import softmax\n",
    "\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# Generate a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models = ['pythia-12b', 'pythia-6.9b', 'pythia-2.8b', 'pythia-1.4b', 'pythia-410m', 'pythia-160m', 'pythia-70m', 'pythia-31m', 'pythia-14m']\n",
    "# large_models = ['pythia-12b', 'pythia-6.9b', 'pythia-2.8b', 'pythia-1.4b']\n",
    "# small_models = ['pythia-410m', 'pythia-160m', 'pythia-70m', 'pythia-31m', 'pythia-14m']\n",
    "\n",
    "# all_models = ['OLMo-1B', 'OLMo-7B', 'OLMo-7B-SFT', 'OLMo-7B-Instruct']\n",
    "# large_models = ['OLMo-7B', 'OLMo-7B-SFT', 'OLMo-7B-Instruct']\n",
    "# small_models = ['OLMo-1B']\n",
    "\n",
    "all_models = ['pythia-12b', 'pythia-6.9b', 'open-instruct-pythia-6.9b-tulu']\n",
    "\n",
    "N_GRAMS = 5\n",
    "# BASE_DIR = \"./results/n-grams/mmlu/test-set/exp_full_None\"\n",
    "CORPUS = \"pile\"\n",
    "DATASET = \"mmlu\"\n",
    "TASKS = CONFIG.mmlu_tasks['top_diff_sft_olmo']\n",
    "OMMIT_TASKS = True\n",
    "POST_FILTER = True\n",
    "\n",
    "BASE_DIR = PATHS.base_ngram_paths[DATASET][CORPUS]['base_path']\n",
    "BASE_PATH = os.path.join(BASE_DIR, f\"{N_GRAMS}\")\n",
    "METHOD = \"0-shot_common\"\n",
    "BASE_PATH_COMMON = os.path.join(BASE_PATH, \"common\")\n",
    "BASE_PATH_ALL = os.path.join(BASE_PATH, \"all\")\n",
    "FIG_DIR = os.path.join(\"/share/edc/home/antonis/LLM-Incidental-Supervision/incidental-supervision/figures\", DATASET, CORPUS)\n",
    "if not os.path.exists(FIG_DIR):\n",
    "    os.makedirs(FIG_DIR)\n",
    "\n",
    "print(f\"BASE PATH: {BASE_PATH}\")\n",
    "\n",
    "TASKS_OMMIT = CONFIG.task_configs[DATASET]['ommit']\n",
    "\n",
    "def remove_nested_lists(df):\n",
    "    for col in df.columns:\n",
    "        # Check if any element in the column is a list or an array\n",
    "        if any(isinstance(x, (list, np.ndarray)) for x in df[col]):\n",
    "            print(f\"Flattening column: {col}\")\n",
    "            # Apply a lambda function to select the first element if it is a list or an array, otherwise keep the element as is\n",
    "            df[col] = df[col].apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x)\n",
    "    return df\n",
    "\n",
    "def normalize_data(group):\n",
    "    min_value = group.min()\n",
    "    max_value = group.max()\n",
    "    # Check if all values are the same\n",
    "    if max_value - min_value == 0:\n",
    "        # Return a default value or the original values\n",
    "        return pd.Series([0.5] * len(group), index=group.index)\n",
    "    else:\n",
    "        return (group - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_all_models_pth = os.path.join(BASE_PATH, f\"examples_dfs_{METHOD}_models.pkl\")\n",
    "# dfs_all_models_pth = \"./results/n-grams/mmlu/pile/exp4_filter/test-set/exp_full_None/5/examples_dfs_common_models.pkl\"\n",
    "\n",
    "# load pickle\n",
    "with open(dfs_all_models_pth, \"rb\") as f:\n",
    "    dfs_all_models = pickle.load(f)\n",
    "\n",
    "# keep only specific tasks\n",
    "if TASKS is not None:\n",
    "    dfs_all_models = {model: df[df['task'].isin(TASKS)] for model, df in dfs_all_models.items()}\n",
    "\n",
    "# keep only the models we are interested in\n",
    "dfs_all_models = {model: dfs_all_models[model] for model in all_models}\n",
    "df_all_models = pd.concat(\n",
    "    [df.assign(model=model_name) for model_name, df in dfs_all_models.items()]\n",
    ")\n",
    "df_all_models = remove_nested_lists(df_all_models)\n",
    "\n",
    "df_all_models.head(1)\n",
    "\n",
    "# create a perplexity column\n",
    "for model in dfs_all_models:\n",
    "    dfs_all_models[model][\"perplexity_gold\"] = dfs_all_models[model][\"probs_gold\"].apply(lambda x: 2 ** -np.log2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "note: probs_softmax is the normalized probability of the 4 choices (sums to 1)\n",
    "      probs_nll is the actual probability assigned by the model (converted from nll to probability)\n",
    "\n",
    "value: the occurences of a specific ngram\n",
    "count: the number of occurences per example\n",
    "sum: the sum of the occurences of the ngram in the whole dataset\n",
    "\"\"\"\n",
    "\n",
    "models = list(dfs_all_models.keys())\n",
    "model_colormap = plt.cm.get_cmap('coolwarm', len(models))\n",
    "model_color_mapping = {model: model_colormap(1 - i / len(models)) for i, model in enumerate(models)}\n",
    "print(models)\n",
    "\n",
    "if OMMIT_TASKS:\n",
    "    print(f\"OMMITING TASKS: {TASKS_OMMIT}\")\n",
    "    df_all_models = df_all_models[~df_all_models[\"task\"].isin(TASKS_OMMIT)]\n",
    "\n",
    "if POST_FILTER:\n",
    "    print(\"POST FILTERING\")\n",
    "    df_all_models = post_filter(df_all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models.iloc[0]['example']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns where column A != column Answer\n",
    "df_all_models_correct = df_all_models[df_all_models['A'] == df_all_models['answer']]\n",
    "df_all_models_incorrect = df_all_models[df_all_models['A'] != df_all_models['answer']]\n",
    "\n",
    "p_correct = len(df_all_models_correct) / len(df_all_models)\n",
    "p_incorrect = len(df_all_models_incorrect) / len(df_all_models)\n",
    "print(f\"Correct: {p_correct:.2f}, Incorrect: {p_incorrect:.2f}\")\n",
    "\n",
    "correct_mean_value = df_all_models_correct['value'].mean()\n",
    "incorrect_mean_value = df_all_models_incorrect['value'].mean()\n",
    "print(f\"Correct Mean Value: {correct_mean_value} \\\n",
    "        Incorrect Mean Value: {incorrect_mean_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(dfs_all_models.keys())\n",
    "model_colormap = plt.cm.get_cmap('coolwarm', len(models))\n",
    "model_color_mapping = {model: model_colormap(1 - i / len(models)) for i, model in enumerate(models)}\n",
    "variable = 'probs_softmax'\n",
    "# variable = 'probs'\n",
    "models_ommit = [] # ['pythia-410m'] # ['pythia-31m'] # ['pythia-6.9b']\n",
    "normalize = True\n",
    "\n",
    "n_groups = 10\n",
    "lower_percentile = 0.2\n",
    "upper_percentile = 1 - lower_percentile\n",
    "\n",
    "# Calculate the mean value for each probability group across all models\n",
    "probs_gold_all = df_all_models[f'{variable}_gold']\n",
    "if normalize:\n",
    "    # Apply the normalization function to the f'{variable}_gold' column grouped by 'model'\n",
    "    df_all_models[f'{variable}_gold_normalized'] = df_all_models.groupby('model')[f'{variable}_gold'].transform(normalize_data)\n",
    "    probs_gold_range = np.linspace(0, 1, n_groups+1)\n",
    "    df_all_models[f'{variable}_gold_range'] = pd.cut(df_all_models[f'{variable}_gold_normalized'], bins=probs_gold_range)\n",
    "else:\n",
    "    probs_gold_range = np.linspace(0, np.max(probs_gold_all), n_groups+1)\n",
    "    df_all_models[f'{variable}_gold_range'] = pd.cut(probs_gold_all, bins=probs_gold_range)\n",
    "\n",
    "\n",
    "print(df_all_models['model'].unique())\n",
    "\n",
    "# convert categorical to numerical\n",
    "df_all_models[f'{variable}_gold_range'] = df_all_models[f'{variable}_gold_range'].apply(lambda x: x.mid).astype(float)\n",
    "\n",
    "# cut the \"sum\" column\n",
    "n_groups_sum = 25\n",
    "df_all_models['count_range'] = pd.cut(df_all_models['count'], bins=n_groups_sum)\n",
    "df_all_models['count_range'] = df_all_models['count_range'].apply(lambda x: x.mid).astype(float)\n",
    "\n",
    "# get the accuracy per count_range\n",
    "# accuracy_count = df_all_models.groupby('count_range')['accuracy'].transform('mean').reset_index(name='accuracy_count')\n",
    "df_all_models['accuracy_count_model'] = df_all_models.groupby(['count_range', 'model'])['accuracy'].transform('mean')\n",
    "\n",
    "# compute accuracy per task and split into ranzge\n",
    "n_groups_acc = 10\n",
    "df_all_models['accuracy_range'] = pd.cut(df_all_models['ds_score'], bins=n_groups_acc)\n",
    "df_all_models['accuracy_range'] = df_all_models['accuracy_range'].apply(lambda x: x.mid).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ = 'sum'\n",
    "df_all_models[var_] = pd.to_numeric(df_all_models[var_], errors='coerce')\n",
    "# top_k = df_all_models[var_].unique().quantile(0.9)\n",
    "var_indexes = df_all_models[var_].nlargest(10).index\n",
    "df_top_ranges = df_all_models.loc[var_indexes]\n",
    "df_top_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Assuming df_all_models is your DataFrame and 'task' and var_ are columns in your DataFrame\n",
    "\n",
    "# Create the bar chart using plotly express\n",
    "fig = px.histogram(df_all_models, x='value', color='task', \n",
    "                   hover_data=['task'], nbins=100,\n",
    "                   title='Distribution of Values per Task')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all_models['task'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ommit_tasks = ['high_school_computer_science', 'elementary_mathematics',\n",
    "               'college_computer_science', 'high_school_mathematics', \n",
    "               'public_relations', 'nutrition',\n",
    "               'machine_learning', 'college_mathematics'] # miscellaneous\n",
    "\n",
    "df_model = df_all_models[df_all_models['model'] == 'pythia-12b']\n",
    "\n",
    "task_list = df_model['task'].unique()\n",
    "df_model['value'] = pd.to_numeric(df_model['value'], errors='coerce')\n",
    "\n",
    "# create empty df\n",
    "df_ngram_task_top10 = pd.DataFrame()\n",
    "for task in task_list:\n",
    "    print(f\"------ {task} ------\")\n",
    "    df_model_task = df_model[df_model['task'] == task]\n",
    "    df_model_task_top10 = df_model_task.nlargest(10, 'value')\n",
    "    display(df_model_task.sort_values('value', ascending=False))\n",
    "    df_ngram_task_top10 = pd.concat([df_ngram_task_top10, df_model_task_top10])\n",
    "\n",
    "# save\n",
    "df_ngram_task_top10.to_csv(f\"{BASE_PATH}/top10_ngrams_per_task.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.wimbd_ import post_filter\n",
    "\n",
    "task = 'nutrition'\n",
    "\n",
    "df_examples_all_task = df_all_models[df_all_models['task'] == task]\n",
    "df_examples_all_task.head(1)\n",
    "\n",
    "# df_examples_all_task = post_filter(df_examples_all_task)\n",
    "\n",
    "# df_examples_all_task_2 = df_examples_all_task.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep \n",
    "df_examples_task_ommited = df_all_models[~df_all_models['task'].isin(ommit_tasks)]\n",
    "# df_examples_all_filtered = post_filter(df_all_models.copy())\n",
    "# df_examples_all_filtered = df_examples_all_filtered[~df_examples_all_filtered['task'].isin(ommit_tasks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar chart using plotly express\n",
    "fig = px.histogram(df_all_models, x='value', color='task', \n",
    "                   hover_data=['task'], nbins=100,\n",
    "                   title='Distribution of Values per Task')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot count_range vs. accuracy_count\n",
    "\n",
    "# first groupby example\n",
    "df_all_models_example = df_all_models.groupby(['example_str', 'model']).first().reset_index()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "N_SAMPLES = None\n",
    "\n",
    "for n, model in enumerate(models):\n",
    "    if model in models_ommit:\n",
    "        continue\n",
    "    df_model = df_all_models_example[df_all_models_example['model'] == model]\n",
    "    \n",
    "    # Calculate mean and standard deviation for each count range\n",
    "    grouped = df_model.groupby('count_range')['accuracy_count_model']\n",
    "    n_examples = grouped.count()\n",
    "\n",
    "    print(f\"---------- model: {model} ----------\")\n",
    "    # if n == 0:\n",
    "        # print(f\"{n_examples}\")\n",
    "    \n",
    "    if N_SAMPLES is not None:\n",
    "        sufficient_samples = n_examples[n_examples >= N_SAMPLES].index\n",
    "        df_model_sufficient = df_model[df_model['count_range'].isin(sufficient_samples)]\n",
    "        df_model_sampled = df_model_sufficient.groupby('count_range').apply(lambda x: x.sample(n=N_SAMPLES, random_state=1)).reset_index(drop=True)\n",
    "    else:\n",
    "        sufficient_samples = n_examples.index\n",
    "        df_model_sufficient = df_model[df_model['count_range'].isin(sufficient_samples)]\n",
    "        df_model_sampled = df_model_sufficient.reset_index(drop=True)\n",
    "    \n",
    "    print(df_model_sampled)\n",
    "    \n",
    "    # Recalculate mean and standard deviation for the sampled data\n",
    "    grouped_sampled = df_model_sampled.groupby('count_range')['accuracy_count_model']\n",
    "    mean_sampled = grouped_sampled.mean()\n",
    "    std_sampled = grouped_sampled.std()\n",
    "\n",
    "    # Plot the mean accuracy count model for the sampled data\n",
    "    plt.plot(mean_sampled.index, mean_sampled.values, label=model, color=model_color_mapping[model])\n",
    "    \n",
    "    # Plot the scatter points for the sampled data\n",
    "    plt.scatter(df_model_sampled['count_range'], df_model_sampled['accuracy_count_model'], color=model_color_mapping[model], s=10)\n",
    "    \n",
    "    # Add the shaded error margin for the sampled data\n",
    "    plt.fill_between(mean_sampled.index, mean_sampled.values - std_sampled.values, mean_sampled.values + std_sampled.values, color=model_color_mapping[model], alpha=0.2)\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Count')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.4, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models_example.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_str = df_all_models_example.iloc[0]['example_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models_example['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models_example[df_all_models_example['example_str'] == example_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualize import plot_accuracy_vs_count_with_fit\n",
    "\n",
    "df_all_models_example_range = df_all_models_example[df_all_models_example['count'] < 500]\n",
    "\n",
    "plot_accuracy_vs_count_with_fit(df_all_models_example_range, models, \n",
    "                                models_ommit, model_color_mapping,\n",
    "                                x='count', y='probs_softmax_gold',\n",
    "                                degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models_example[df_all_models_example['value'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models_example[df_all_models_example['count'] > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models_example['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut lower and upper percentiles per group and concatenate the results\n",
    "ranges = df_all_models[f'{variable}_gold_range'].unique()\n",
    "filtered_df_all_models = pd.DataFrame()\n",
    "\n",
    "for r in ranges:\n",
    "    df_r = df_all_models[df_all_models[f'{variable}_gold_range'] == r]\n",
    "\n",
    "    # if normalize:\n",
    "    #     df_r[f'{variable}_gold_range'] /= df_r[f'{variable}_gold_range'].max()\n",
    "\n",
    "    lower_value = df_r['value'].quantile(lower_percentile)\n",
    "    upper_value = df_r['value'].quantile(upper_percentile)\n",
    "    # Filter the group DataFrame and concatenate it to the filtered DataFrame\n",
    "    filtered_df_r = df_r[(df_r['value'] >= lower_value) & (df_r['value'] <= upper_value)]\n",
    "\n",
    "    filtered_df_all_models = pd.concat([filtered_df_all_models, filtered_df_r])\n",
    "\n",
    "    # Print (lower_value, upper_value) and max and min for each range\n",
    "    # print(f\"{r}: {df_r['value'].min()} - {df_r['value'].max()} -> {lower_value} - {upper_value}\")\n",
    "df_all_models = filtered_df_all_models\n",
    "# Calculate the mean value for each probability group across all models\n",
    "mean_values_all = df_all_models.groupby(f'{variable}_gold_range')['value'].mean()\n",
    "\n",
    "# Create a line plot of mean_value vs. probs_softmax_gold for all models\n",
    "plt.plot(mean_values_all.index.unique(), \n",
    "         mean_values_all.values,\n",
    "         label='All Models',\n",
    "         color='black')  # choose a color that stands out\n",
    "\n",
    "plt.scatter(mean_values_all.index.unique(),\n",
    "            mean_values_all.values,\n",
    "            color='red', marker='x', s=100)\n",
    "\n",
    "plt.xlabel(f'{variable}_gold')\n",
    "plt.ylabel('Mean # ngrams')\n",
    "plt.legend()\n",
    "plt.title(f'Mean  vs. {variable}_gold, (all models)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values_all = {}\n",
    "\n",
    "models_ommit = []\n",
    "\n",
    "for model in df_all_models['model'].unique():\n",
    "    if model in models_ommit:\n",
    "        continue\n",
    "    \n",
    "    df_model = df_all_models[df_all_models['model'] == model]\n",
    "    if normalize:\n",
    "        # Apply the normalization function to the f'{variable}_gold' column grouped by 'model'\n",
    "        df_model.loc[:, f'{variable}_gold_normalized'] = df_model.groupby('model')[f'{variable}_gold'].transform(normalize_data)\n",
    "        probs_gold = df_model[f'{variable}_gold_normalized']\n",
    "    else:\n",
    "        probs_gold = df_model[f'{variable}_gold']\n",
    "\n",
    "    df_model.loc[:, f'{variable}_gold_range'] = pd.cut(probs_gold, bins=probs_gold_range)\n",
    "\n",
    "    # keep percentile range of value\n",
    "    # lower_value = df_model['value'].quantile(lower_percentile)\n",
    "    # upper_value = df_model['value'].quantile(upper_percentile)\n",
    "    # df_model = df_model[(df_model['value'] >= lower_value) & (df_model['value'] <= upper_value)]\n",
    "\n",
    "    # Calculate the mean value for each probability group\n",
    "    mean_values = df_model.groupby(f'{variable}_gold_range')['value'].mean()\n",
    "    mean_values_all[model] = mean_values\n",
    "\n",
    "    # Create a line plot of mean_value vs.f {variable}_gold_range\n",
    "    plt.plot(mean_values.index.categories.mid, \n",
    "             mean_values.values,\n",
    "             label=model,\n",
    "             color=model_color_mapping[model])\n",
    "    # scatter plot\n",
    "    plt.scatter(mean_values.index.categories.mid,\n",
    "                mean_values.values,\n",
    "                color=model_color_mapping[model], marker='x', s=50, alpha=0.5)\n",
    "\n",
    "    plt.xlabel(f'{variable}_gold')\n",
    "    plt.ylabel('Mean # ngrams')\n",
    "    plt.legend()\n",
    "\n",
    "plt.title(f'Mean # ngrams vs. {variable}_gold_range, (per model)')\n",
    "\n",
    "plt.savefig(os.path.join(FIG_DIR, f\"mean_ngrams_vs_{variable}_gold.png\"))\n",
    "\n",
    "df_mean_values_all = pd.DataFrame(mean_values_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debugging code\n",
    "# chosen_model = 'pythia-70m'\n",
    "# chosen_cateory = \"(0.98, 0.99]\"\n",
    "# chosen_interval = pd.Interval(0.98, 0.99, closed='right')\n",
    "# df_chosen_model = df_all_models[df_all_models['model'] == chosen_model]\n",
    "# df_chosen_model = df_chosen_model[df_chosen_model[f'{variable}_gold_range'].apply(lambda x: x == chosen_interval)]\n",
    "# df_chosen_model\n",
    "\n",
    "# phrase = ['reliability validity test']\n",
    "# df_all_models[df_all_models['index'].str.contains('reliability validity test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_values_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of models to include\n",
    "included_models = ['pythia-12b']\n",
    "\n",
    "# Get unique tasks\n",
    "unique_tasks = df_all_models['task'].unique()\n",
    "\n",
    "# Set up the colormap for tasks\n",
    "task_colormap = plt.cm.get_cmap('viridis', len(unique_tasks))\n",
    "task_color_mapping = {task: task_colormap(i / len(unique_tasks)) for i, task in enumerate(unique_tasks)}\n",
    "\n",
    "# df_all_models[f'{variable}_gold_range'] = pd.cut(df_all_models[f'{variable}_gold'], bins=4)  # This should be done before the loop\n",
    "\n",
    "# Iterate over the tasks and models to plot\n",
    "for n, task in enumerate(unique_tasks):\n",
    "    \n",
    "    for model in included_models:\n",
    "        # Filter the DataFrame for the current task and model\n",
    "        df_model = df_all_models[df_all_models['model'] == model]\n",
    "        df_task_model = df_model[df_model['task'] == task].copy()  # Make a copy to avoid SettingWithCopyWarning\n",
    "        \n",
    "        # Skip if there's no data for this task in the model\n",
    "        if df_task_model.empty:\n",
    "            continue\n",
    "        \n",
    "        # Normalize the 'value' column for the current task\n",
    "        df_task_model['normalized_value'] = normalize_data(df_task_model['value'])\n",
    "        \n",
    "        # Calculate the mean value for each probability group for the current task and model\n",
    "        mean_values = df_task_model.groupby(f'{variable}_gold_range')['normalized_value'].mean()\n",
    "        \n",
    "        # Extract the midpoints from the interval index\n",
    "        mid_points = [interval for interval in mean_values.index]\n",
    "        \n",
    "        # Create a line plot of mean_value vs. {variable}_gold_range for the current task and model\n",
    "        line, = plt.plot(mid_points, \n",
    "                         mean_values.values,\n",
    "                         label=task,\n",
    "                         color=task_color_mapping[task])\n",
    "        \n",
    "        # Scatter plot\n",
    "        plt.scatter(mid_points,\n",
    "                    mean_values.values,\n",
    "                    color=task_color_mapping[task], marker='x', s=50)\n",
    "        \n",
    "\n",
    "# Set labels, legend, and title\n",
    "plt.xlabel(f'{variable}_gold')\n",
    "plt.ylabel('Normalized Mean # ngrams')\n",
    "# plt.legend(title='Task', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.title(f'Normalized Mean # ngrams vs. {variable}_gold_range, per task (selected models)')\n",
    "plt.tight_layout()  # Adjust layout to make room for the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of models to include\n",
    "# included_models = list(dfs_all_models.keys())\n",
    "# included_models = large_models\n",
    "# included_models = small_models\n",
    "included_models = ['pythia-12b']\n",
    "\n",
    "# Get unique tasks where ds_score >= min_acc\n",
    "min_acc = 0.01\n",
    "unique_tasks = df_all_models[df_all_models['ds_score'] >= min_acc].groupby('task')['ds_score'].mean().sort_values(ascending=False).index\n",
    "\n",
    "# Determine the layout of the subplots\n",
    "n_cols = 6  # Adjust the number of columns as needed\n",
    "n_rows = int(np.ceil(len(unique_tasks) / n_cols))  # Adjust the number of rows as needed\n",
    "\n",
    "# Create a figure and a grid of subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 3))  # Adjust the figure size as needed\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "# Set up the colormap for tasks\n",
    "task_colormap = plt.cm.get_cmap('viridis', len(unique_tasks))\n",
    "task_color_mapping = {task: task_colormap(i / len(unique_tasks)) for i, task in enumerate(unique_tasks)}\n",
    "\n",
    "# Function to normalize data\n",
    "def normalize_data(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "points_delta = []\n",
    "\n",
    "# Iterate over the tasks and models to plot\n",
    "for n, task in enumerate(unique_tasks):\n",
    "    ax = axes[n]  # Get the corresponding subplot axis\n",
    "    \n",
    "    for i, model in enumerate(included_models):\n",
    "        # Filter the DataFrame for the current task and model\n",
    "        df_model = df_all_models[df_all_models['model'] == model]\n",
    "        df_task_model = df_model[df_model['task'] == task].copy()  # Make a copy to avoid SettingWithCopyWarning\n",
    "        \n",
    "        # Skip if there's no data for this task in the model\n",
    "        if df_task_model.empty:\n",
    "            continue\n",
    "        \n",
    "        # # Normalize the 'value' column for the current task\n",
    "        # df_task_model['normalized_value'] = normalize_data(df_task_model['value'])\n",
    "        \n",
    "        # # Calculate the mean value for each probability group for the current task and model\n",
    "        # mean_values = df_task_model.groupby(f'{variable}_gold_range')['normalized_value'].mean()\n",
    "\n",
    "        # # keep percentile range of value\n",
    "        # lower_value = df_task_model['value'].quantile(lower_percentile)\n",
    "        # upper_value = df_task_model['value'].quantile(upper_percentile)\n",
    "        # df_task_model = df_task_model[(df_task_model['value'] >= lower_value) & (df_task_model['value'] <= upper_value)]\n",
    "\n",
    "        # assign probability group for task\n",
    "        probs_gold_task = df_task_model[f'{variable}_gold']\n",
    "        probs_gold_task_range = np.linspace(0, np.max(probs_gold_task), n_groups+1)\n",
    "        df_task_model[f'{variable}_gold_range'] = pd.cut(probs_gold_task, bins=probs_gold_task_range)\n",
    "\n",
    "        mean_values = df_task_model.groupby(f'{variable}_gold_range')['value'].mean()\n",
    "\n",
    "        # After calculating mean_values and before plotting\n",
    "        mean_values = mean_values.dropna()\n",
    "\n",
    "        # Now, we need to make sure that the categories in the index match the mean_values\n",
    "        # We will filter out the categories that correspond to NaN mean values\n",
    "        valid_intervals = mean_values.index[~mean_values.isna()]\n",
    "\n",
    "        # Extract the midpoints from the valid intervals\n",
    "        mid_points = [interval.mid for interval in valid_intervals]\n",
    "\n",
    " \n",
    "        # Create a line plot of mean_value vs. {variable}_gold_range for the current task and model\n",
    "        ax.plot(mid_points, \n",
    "                mean_values.values,\n",
    "                label=task,\n",
    "                color=task_color_mapping[task])\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(mid_points,\n",
    "                   mean_values.values,\n",
    "                   color=task_color_mapping[task], marker='x', s=50)\n",
    "\n",
    "        ds_score = df_task_model['ds_score'].mean()\n",
    "        ax.text(0.5, 0.9, f'DS Score: {ds_score:.2f}', \n",
    "            transform=ax.transAxes, ha='center', va='center', \n",
    "            fontsize=10, bbox=dict(facecolor='white', alpha=0.5))\n",
    "        \n",
    "        # track if last value is greater than first value\n",
    "        if mean_values.values[-1] > mean_values.values[0]:\n",
    "            points_delta.append(1)\n",
    "        else:\n",
    "            points_delta.append(0)\n",
    "        \n",
    "\n",
    "        if i == 0:\n",
    "            # Set labels and title for each subplot\n",
    "            ax.set_xlabel(f'{variable}_gold')\n",
    "            ax.set_ylabel('Normalized Mean # ngrams')\n",
    "            ax.set_title(f'Task: {task}')\n",
    "            # ax.legend()\n",
    "\n",
    "# Set the title for the entire figure\n",
    "fig.suptitle(f\"\"\"Normalized Mean # ngrams vs. {variable}_gold_range,\\ \n",
    "                 per task (selected models): increase \n",
    "             on {sum(points_delta)}/{len(points_delta)} tasks\"\"\",\n",
    "               y=1.02, fontsize=23)\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, f\"mean_ngrams_vs_{variable}_gold_per_task.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum sample size across all probability groups\n",
    "group_sizes = df_all_models.groupby(f'{variable}_gold_range').size()\n",
    "min_samples = group_sizes.min()\n",
    "\n",
    "# Function to sample n points from each group\n",
    "def sample_n_from_group(group, n=min_samples):\n",
    "    return group.sample(n=n, random_state=1) if len(group) > n else group\n",
    "\n",
    "# Sample uniformly from each group\n",
    "df_sampled_all_models = df_all_models.groupby(f'{variable}_gold_range').apply(sample_n_from_group).reset_index(drop=True)\n",
    "df_sampled_large_models = df_all_models[df_all_models['model'].isin(large_models)].groupby(f'{variable}_gold_range').apply(sample_n_from_group).reset_index(drop=True)\n",
    "df_sampled_small_models = df_all_models[df_all_models['model'].isin(small_models)].groupby(f'{variable}_gold_range').apply(sample_n_from_group).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_models.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_mean_values(df, model_group, color, label, fig_dir, variable_gold_range, file_suffix,\n",
    "                     log_axis=False, flip_axes=False):\n",
    "    # Group by the probability range and calculate mean and standard deviation\n",
    "    grouped = df.groupby(f'{variable_gold_range}')\n",
    "    mean_values = grouped['value'].mean().astype(float)\n",
    "    std_values = grouped['value'].std().astype(float)\n",
    "\n",
    "    # Extract the midpoints for the x-axis if they are interval indices, otherwise use as is\n",
    "    if isinstance(mean_values.index, pd.IntervalIndex):\n",
    "        mid_points = mean_values.index.mid.tolist()\n",
    "    else:\n",
    "        mid_points = mean_values.index.tolist()\n",
    "\n",
    "    if flip_axes:\n",
    "        # Flip the axes\n",
    "        plt.plot(mid_points, \n",
    "                 mean_values.values,\n",
    "                 label=label,\n",
    "                 color=color)\n",
    "        plt.fill_between(mid_points, \n",
    "                         (mean_values.values - std_values).astype(float), \n",
    "                         (mean_values.values + std_values).astype(float), \n",
    "                         color=color, alpha=0.1)\n",
    "        plt.scatter(mid_points,\n",
    "                    mean_values.values,\n",
    "                    color=color, marker='x', s=100)\n",
    "        plt.xlabel(f'{variable_gold_range}')\n",
    "        plt.ylabel('Mean # ngrams')\n",
    "    else:\n",
    "        # Normal axes\n",
    "        plt.plot(mean_values.values, \n",
    "                 mid_points,\n",
    "                 label=label,\n",
    "                 color=color)\n",
    "        plt.fill_betweenx(mid_points, \n",
    "                          (mean_values.values - std_values).astype(float), \n",
    "                          (mean_values.values + std_values).astype(float), \n",
    "                          color=color, alpha=0.1)\n",
    "        plt.scatter(mean_values.values,\n",
    "                    mid_points,\n",
    "                    color=color, marker='x', s=100)\n",
    "        plt.ylabel(f'{variable_gold_range}')\n",
    "        plt.xlabel('Mean # ngrams')\n",
    "\n",
    "    # Set the title and legend\n",
    "    plt.title(f'Mean # ngrams vs. {variable_gold_range}')\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Optionally, set the x-axis to log scale\n",
    "    if log_axis:\n",
    "        plt.xscale('log')\n",
    "\n",
    "    # Save the figure if a directory is provided\n",
    "    if fig_dir:\n",
    "        plt.savefig(os.path.join(fig_dir, f\"mean_ngrams_vs_{variable_gold_range}_{file_suffix}.png\"))\n",
    "\n",
    "\n",
    "\n",
    "log_axis = False\n",
    "flip_axes = True\n",
    "# Usage example:\n",
    "plot_var = f'{variable}_gold_range'\n",
    "# plot_mean_values(df_all_models, 'all_models', 'black', 'All Models', FIG_DIR, plot_var, 'all')\n",
    "plot_mean_values(df_all_models[df_all_models['model'].isin(large_models)], 'large_models', 'red', 'Large Models', FIG_DIR, plot_var, 'large', \n",
    "                 log_axis=log_axis, flip_axes=flip_axes)\n",
    "plot_mean_values(df_all_models[df_all_models['model'].isin(small_models)], 'small_models', 'blue', 'Small Models', FIG_DIR, plot_var, 'small',\n",
    "                 log_axis=log_axis, flip_axes=flip_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Define the order of models\n",
    "all_models = [\n",
    "    'pythia-12b', 'pythia-6.9b', 'pythia-2.8b', 'pythia-1.4b',\n",
    "    'pythia-410m', 'pythia-160m', 'pythia-70m', 'pythia-31m', 'pythia-14m'\n",
    "]\n",
    "\n",
    "# Create legend handles\n",
    "legend_handles = [mpatches.Patch(color=model_color_mapping[model], label=model) for model in all_models]\n",
    "\n",
    "# Get unique tasks\n",
    "unique_tasks = sorted(df_all_models['task'].unique())\n",
    "\n",
    "# Determine the layout of the subplots\n",
    "n_cols = 5  # Adjust the number of columns as needed\n",
    "n_rows = int(np.ceil(len(unique_tasks) / n_cols))  # Adjust the number of rows as needed\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_rows * 9, n_rows * 4.5))  # Adjust the figure size as needed\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "for n, task in enumerate(unique_tasks):\n",
    "    ax = axes[n]  # Get the corresponding subplot axis\n",
    "    task_avg_ds_score = df_all_models[df_all_models['task'] == task].groupby('model')['model_ds_score'].mean()\n",
    "    task_avg_ds_score = task_avg_ds_score.reindex(all_models)\n",
    "    task_avg_ds_score.plot(kind='bar', ax=ax, color=[model_color_mapping[model] for model in all_models])\n",
    "    ax.set_title(task)\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('Average ds_score')\n",
    "\n",
    "# Adjust the layout to make room for the titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add the legend outside of the last subplot\n",
    "plt.legend(handles=legend_handles, bbox_to_anchor=(1.05, 1), loc='upper left', title='Model')\n",
    "\n",
    "plt.savefig(os.path.join(FIG_DIR, f\"average_ds_score_per_task.png\"))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_tasks = ['arithmetic_1dc', 'arithmetic_2da', 'arithmetic_2dm', \n",
    "#               'arithmetic_2ds', 'arithmetic_3da', 'arithmetic_3ds',]\n",
    "\n",
    "# df_all_models_tasks = df_all_models[df_all_models['task'].isin(plot_tasks)]\n",
    "\n",
    "flip_axes = True\n",
    "log_axis = False\n",
    "plot_var = 'accuracy_range'\n",
    "plot_mean_values(df_all_models[df_all_models['model'].isin(large_models)], \n",
    "                 'large_models', 'red', 'Large Models', FIG_DIR, plot_var, 'large',\n",
    "                 log_axis=log_axis, flip_axes=flip_axes)\n",
    "plot_mean_values(df_all_models[df_all_models['model'].isin(small_models)], 'small_models', 'blue', \n",
    "                 'Small Models', FIG_DIR, plot_var, 'small',\n",
    "                 flip_axes=flip_axes, log_axis=log_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_values_for_tasks(df, tasks, model_groups, colors, labels, fig_dir, variable_gold_range, file_suffix):\n",
    "    # Determine the layout of the subplots\n",
    "    n_cols = 3  # Adjust the number of columns as needed\n",
    "    n_rows = int(np.ceil(len(tasks) / n_cols))  # Adjust the number of rows as needed\n",
    "\n",
    "    # Create a figure and a grid of subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))  # Adjust the figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes for easy iteration\n",
    "\n",
    "    for i, task in enumerate(tasks):\n",
    "        ax = axes[i]  # Get the corresponding subplot axis\n",
    "        plt.sca(ax)  # Set the current Axes instance to ax\n",
    "\n",
    "        for model_group, color, label in zip(model_groups, colors, labels):\n",
    "            # Filter the DataFrame for the current task and model group\n",
    "            df_task_model_group = df[(df['task'] == task) & (df['model'].isin(model_group))]\n",
    "            # Plot the mean values for the current task and model group\n",
    "            plot_mean_values(df_task_model_group, model_group, color, label, fig_dir, variable_gold_range, f\"{task}_{file_suffix}\", flip_axes=True)\n",
    "\n",
    "        # Set labels and title for each subplot\n",
    "        ax.set_ylabel(f'{variable_gold_range}')  # Swapped x and y labels\n",
    "        ax.set_xlabel('Mean # ngrams')  # Swapped x and y labels\n",
    "        ax.set_title(f'Task: {task}')\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust the layout and save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, f\"mean_ngrams_vs_{variable_gold_range}_all_tasks.png\"))\n",
    "\n",
    "# Define your model groups, colors, and labels\n",
    "model_groups = [\n",
    "    all_models,\n",
    "    large_models,\n",
    "    small_models\n",
    "]\n",
    "colors = ['black', 'red', 'blue']\n",
    "labels = ['All Models', 'Large Models', 'Small Models']\n",
    "\n",
    "tasks = df_all_models['task'].unique()\n",
    "# Usage example:\n",
    "plot_variable = 'accuracy_count_model' \n",
    "# plot_mean_values_for_tasks(df_all_models, tasks, model_groups, colors, labels, FIG_DIR, plot_variable, 'all_tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_all_models is your DataFrame and 'value' is the column you're interested in\n",
    "# variable_gold_range is the name of the column containing the categorical range data\n",
    "\n",
    "n_subgroups = 20  # Number of groups you want to create\n",
    "group_freq = df_all_models.groupby(f'{variable}_gold_range').size()\n",
    "group_freq_min = group_freq.min()  # Minimum frequency across groups\n",
    "n_samples = group_freq_min // n_subgroups  # Number of samples per group\n",
    "\n",
    "# Sample an equal number of data points from each range\n",
    "equal_samples_df = pd.DataFrame()\n",
    "for group_name, group_data in df_all_models.groupby(f'{variable}_gold_range'):\n",
    "    equal_samples_df = pd.concat([equal_samples_df, group_data.sample(n=n_samples, random_state=1)])\n",
    "\n",
    "# Calculate the mean value for each probability group in the equal samples\n",
    "equal_samples_mean_values = equal_samples_df.groupby(f'{variable}_gold_range')['value'].mean()\n",
    "# Extract the midpoints from the interval index for plotting the equal samples average line\n",
    "equal_samples_midpoints = equal_samples_mean_values.index\n",
    "\n",
    "\n",
    "# Create 10 plots\n",
    "for i in range(n_subgroups):\n",
    "    sampled_df = pd.DataFrame()  # Initialize a DataFrame to hold sampled data\n",
    "\n",
    "    # Sample data from each group\n",
    "    for group_name, group_data in df_all_models.groupby(f'{variable}_gold_range'):\n",
    "        sampled_data = group_data.sample(n=min(n_samples, len(group_data)), random_state=i)\n",
    "        sampled_df = pd.concat([sampled_df, sampled_data])\n",
    "\n",
    "    # Calculate the mean value for each probability group in the sampled data\n",
    "    mean_values_sampled = sampled_df.groupby(f'{variable}_gold_range')['value'].mean()\n",
    "\n",
    "    # Extract the midpoints from the interval index for plotting\n",
    "    midpoints = mean_values_sampled.index\n",
    "\n",
    "    # Plot the mean values for the sampled data\n",
    "    plt.plot(midpoints, \n",
    "             mean_values_sampled.values,\n",
    "             label=f'Sampled Set {i+1}',\n",
    "             marker='o')  # Use a marker for each point\n",
    "\n",
    "    # Optional: make y axis log\n",
    "    # plt.yscale('log')\n",
    "\n",
    "    # Set plot title and labels\n",
    "    plt.title(f'Mean # ngrams vs. {variable}_gold_range (Sampled Set {i+1})')\n",
    "    plt.xlabel(f'{variable}_gold_range')\n",
    "    plt.ylabel('Mean # ngrams')\n",
    "\n",
    "# Plot the equal samples average line\n",
    "plt.plot(equal_samples_midpoints, \n",
    "            equal_samples_mean_values.values,\n",
    "            label='Equal Samples Average',\n",
    "            color='red', linestyle='--',\n",
    "            linewidth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value for each probability group\n",
    "mean_values = df_all_models.groupby(f'{variable}_gold_range')['value'].mean()\n",
    "\n",
    "ranges = mean_values.index\n",
    "\n",
    "# only sample according to the group with the least samples\n",
    "n_samples = min([len(df_all_models[df_all_models[f'{variable}_gold_range'] == range_]) for range_ in ranges])\n",
    "\n",
    "# plot dist plot for each range, overlaid\n",
    "for i, range_ in enumerate(ranges):\n",
    "    df_range = df_all_models[df_all_models[f'{variable}_gold_range'] == range_]\n",
    "    indexes = np.random.choice(df_range.index, n_samples, replace=False)\n",
    "    df_range = df_range.loc[indexes]\n",
    "    plt.hist(df_range[f'{variable}_gold'], bins=50, alpha=0.5, label=range)\n",
    "    plt.xlabel(f'{variable}_gold')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "# plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incidental3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
