{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def generate_completion(prompt, max_tokens=100, engine='text-davinci-003'):\n",
    "    response = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    generated_text = response.choices[0].text.strip()\n",
    "    return generated_text\n",
    "\n",
    "# Define your prompt\n",
    "prompt = \"We thought this was one of the worst movies ever. I had to volunteer to watch the end. The romance was not believable; the characters were not developed; the love affair made hardly any sense; it was miscast; and scenery was absolutely stupid because it was either (my opinion) like the ADAMS FAMILY GOES ON VACATION...just creepy, gypsy and cheesy; and the OUTERBANKS does not look typically like those houses on the surf; and who would spend the night in one during a hurricane if it was not theirs. Also..it was not realistic. hurrricanes give you plenty of notice to batten down the hatches.<br /><br />Also the friend was superfluous; and did not match the story What did the civil war have to do with the outerbanks anyway? I also have to mention the wardrobe...did D. Lane have to have a scarf/pashmina/shawl on in every scene? It was overdone. She looked good enough to not have to hide things; without making them obvious like with light slacks.<br /><br />Lastly I am concerned with the impact on our landfills when everyone has to dispose of this stupid, and I mean STUPID movie!!!! Don't fall for the hype on this one!!!!!! We did. Not even watchable. What sentiment does the writer express for the movie?\"\n",
    "prompt = \"How positive is the movie review below?\\nGive a score on a scale from 0 to 1.\\n\\nNot a cozy or ingratiating work, but it's challenging, sometimes clever, and always interesting, and those are reasons enough to see it.\"\n",
    "generate_text = generate_completion(prompt)\n",
    "\n",
    "print(generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import load_scores, compute_metrics\n",
    "bleu_score, meteor_sc = load_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = \"/share/edc/home/antonis/LLM-Incidental-Supervision/incidental-supervision/models/sentiment_c4/P_1_PQA_5_promptsource_True/dataset_1/10-07-23_15:25/eval/checkpoint-84500/inference/07-13-12:01/generated_samples.json\"\n",
    "with open(pth, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "generated_samples = []\n",
    "for d in data:\n",
    "    prompt = d['prompt']\n",
    "    true = d['true']\n",
    "    generated = generate_completion(prompt)\n",
    "    length = min(len(true), len(generated))\n",
    "    generated_comparison = generated[:length]\n",
    "    metrics = compute_metrics(true, generated_comparison,\n",
    "                              bleu_score=bleu_score, meteor_score=meteor_sc)\n",
    "    generated_samples_n = {\n",
    "        'prompt': prompt,\n",
    "        'true': true,\n",
    "        'generated': generated,\n",
    "        \"bleu_score\": metrics['bleu_score'],\n",
    "        \"meteor_score\": metrics['meteor_score'],\n",
    "    }\n",
    "    generated_samples.append(generated_samples_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./models/sentiment_c4/GPT3\"\n",
    "\n",
    "# if not os.path.exists(save_path):\n",
    "#     os.makedirs(save_path)\n",
    "\n",
    "# with open(os.path.join(save_path, 'generated_samples.json'), 'w') as f:\n",
    "#     json.dump(generated_samples, f)\n",
    "\n",
    "from generate import save_generated_samples\n",
    "save_generated_samples(generated_samples, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incidental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
