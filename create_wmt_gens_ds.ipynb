{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from src.wimbd_ import _load_dataset\n",
    "\n",
    "HF_HOME = \"/share/edc/home/antonis/datasets/huggingface\"\n",
    "save_path = os.makedirs(os.path.join(HF_HOME, 'wmt09_gens'), exist_ok=True)\n",
    "\n",
    "base_pth = \"/share/edc/home/antonis/LLM-Incidental-Supervision/incidental-supervision/models/experiment_6_logits_max_4/\"\n",
    "doc_res_files = glob.glob(os.path.join(base_pth, \"**/doc_results.json\"), recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'wmt\\d{2}-(\\w{2}-\\w{2})')\n",
    "language_pairs = [pattern.search(path).group(1) for path in doc_res_files if pattern.search(path)]\n",
    "doc = json.load(open(doc_res_files[0]))\n",
    "\n",
    "def find_lang(path):\n",
    "    pattern = re.compile(r'wmt\\d{2}-(\\w{2}-\\w{2})')\n",
    "    return pattern.search(path).group(1)\n",
    "\n",
    "wmt = _load_dataset('wmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "def insert_gens_into_wmt(wmt, doc_res_files):\n",
    "    for path in tqdm(doc_res_files, desc=\"Processing files\"):\n",
    "        wmt_model = wmt.copy()\n",
    "\n",
    "        with open(path, 'r') as f:\n",
    "            doc_res = json.load(f)\n",
    "\n",
    "        model_name = path.split('/')[-5]\n",
    "        task = path.split('/')[-3]\n",
    "        lang = find_lang(path)\n",
    "        lang1, lang2 = lang.split('-')\n",
    "        total_rows = len(wmt_model[lang]['translation'])\n",
    "        matched_rows = 0\n",
    "        doc_res_task_dict = wmt_model[lang].to_dict()\n",
    "        len_task_dict = len(doc_res_task_dict['translation'])\n",
    "        unmatched_rows = [i for i in range(len_task_dict)]\n",
    "\n",
    "        for doc in tqdm(doc_res[task], desc=f\"Inserting generations for {task}\", leave=False):\n",
    "            src = doc['src']\n",
    "            ref = doc['ref']\n",
    "            gen = doc['result'][0]\n",
    "\n",
    "            for idx in unmatched_rows:\n",
    "                row = doc_res_task_dict['translation'][idx]\n",
    "                # print(row)\n",
    "                if row[lang1] != src and row[lang2] != ref:\n",
    "                    continue\n",
    "                else:\n",
    "                    doc_res_task_dict['translation'][idx]['gen'] = gen\n",
    "                    matched_rows += 1\n",
    "                    unmatched_rows.remove(idx)\n",
    "                    break\n",
    "        \n",
    "        if len(unmatched_rows) > 0:\n",
    "            print(f\"Could not match {len(unmatched_rows)} rows for {task}\")\n",
    "\n",
    "        wmt_model[lang] = Dataset.from_dict(doc_res_task_dict)\n",
    "        dataset_dict = {lang: Dataset.from_dict({'translation': value['translation']}) for lang, value in wmt_model.items()}\n",
    "        dataset_dict = DatasetDict(dataset_dict)\n",
    "        # Now you can save it to disk\n",
    "        dataset_dict.save_to_disk(os.path.join(HF_HOME, f'wmt09_gens_{model_name}'))\n",
    "        print(f\"Matched {matched_rows}/{total_rows} rows for {task}\")\n",
    "\n",
    "    return wmt\n",
    "\n",
    "\n",
    "wmt = insert_gens_into_wmt(wmt, doc_res_files)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dataset_dict = {lang: Dataset.from_dict({'translation': value['translation']}) for lang, value in wmt.items()}\n",
    "# dataset_dict = DatasetDict(dataset_dict)\n",
    "\n",
    "# Now you can save it to disk\n",
    "# dataset_dict.save_to_disk(os.path.join(HF_HOME, 'wmt09_gens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incidental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
